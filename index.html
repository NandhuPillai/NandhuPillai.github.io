<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>f2cd7a9b9c564ffa9d44be99db9e0135</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div id="04c1d497" class="cell code" data-execution_count="3">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># importing libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> f_oneway, tukey_hsd</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span></code></pre></div>
</div>
<div id="917c75ec" class="cell markdown">
<h1 id="what-makes-a-popular-song">What Makes a Popular Song?</h1>
</div>
<div id="bd4d19ad" class="cell markdown">
<h3 id="contributions">Contributions:</h3>
<h3 id="catherine-li">Catherine Li</h3>
<ul>
<li><strong>A:</strong> Chose some datasets to work with, collaborated
in filtering to the current dataset. Suggested working on
popularity.<br />
</li>
<li><strong>C:</strong> Worked on Q1, Correlations<br />
</li>
<li><strong>D/E/F:</strong> Suggested algorithms to consider working on,
worked on Neural Networks and K-Nearest Neighbors<br />
</li>
<li><strong>G:</strong> Wrote the introduction and
insights/conclusion</li>
</ul>
<h3 id="elizabeth-lim">Elizabeth Lim</h3>
<ul>
<li><strong>C:</strong> Helped graph box plots for popularity
distributions between major and minor songs and between explicit and
non-explicit songs<br />
</li>
<li><strong>D/E/F:</strong> Developed and trained Support Vector
Regression and Linear Regression models to analyze which variables
predicted popularity. Visualized both models using graphs to see the
data and regression lines, and analyzed how well the models did.</li>
</ul>
<h3 id="johann-paul">Johann Paul</h3>
<ul>
<li><strong>C:</strong> Compared the distributions of major and minor
keys with respect to popularity, as well as explicit and nonexplicit.
Decided on a Man Whitney U test to test my hypothesis after observing a
lack of normality from the qq-plot.<br />
</li>
<li><strong>D/E/F:</strong> Trained gradient boosted trees using the
xgboost library to predict popularity of songs, and analyzed its
performance. Visualized the distribution of prediction errors as well as
the most important features.<br />
</li>
<li><strong>G:</strong> Helped edit the introduction and Primary
Analysis</li>
</ul>
<h3 id="nandhu-manoj-pillai">Nandhu Manoj Pillai</h3>
<ul>
<li><strong>B:</strong> Preprocessed dataset including encoding the
genre category, cleaning missing data, removed duplicates.<br />
</li>
<li><strong>C:</strong> Worked on Q2 (How popularity was related to
genre and key).<br />
</li>
<li><strong>D/E:</strong> Created RandomForestRegessor and
RandomForestClassifer models and analysis.</li>
</ul>
</div>
<div id="05498f91" class="cell markdown">
<h2 id="i--introduction">I. 🎵 Introduction</h2>
<p>Everyone listens to music 🎧<br />
But have you ever wondered... <strong>what makes a song
<em>popular</em>?</strong> 🤔<br />
How can we predict a song’s success based on just a few key
features?</p>
<p>So many elements go into making music —<br />
🎼 <strong>Key</strong><br />
🎶 <strong>Tempo</strong><br />
🎻 <strong>Instrumentals</strong><br />
🎤 <strong>Vocals</strong><br />
🎧 <strong>Genre</strong>, and more!</p>
<p>People dedicate their <strong>careers — even their lives —</strong>
to creating the next big hit 💿🔥<br />
Wouldn't it be amazing if we could discover a <strong>formula for the
perfect song</strong>? 🎯✨</p>
<p>In this tutorial, we’ll walk you through how we built a
<strong>machine learning model</strong> 🤖<br />
that predicts the <strong>popularity of any song</strong> using just a
handful of features.<br />
Let’s dive in!</p>
<p>Citation: Maharshi Pandya. (2022). 🎹 Spotify Tracks Dataset [Data
set]. Kaggle. <a href="https://doi.org/10.34740/KAGGLE/DSV/4372070"
class="uri">https://doi.org/10.34740/KAGGLE/DSV/4372070</a> This dataset
contains Spotify tracks from over 100 different genres. It includes the
names of the songs, artists, and many different song features such as
danceability, energy, and acousticness. All these features are explained
in more detail on the dataset webpage. We will use this dataset to help
determine which features best predict song popularity.</p>
</div>
<div id="4a3577fc" class="cell markdown">
<h2 id="ii-data-preprocessing">II. Data Preprocessing</h2>
</div>
<div id="e3d9dc6a" class="cell code" data-execution_count="4">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating pandas dataframe of the Spotify dataset.</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>spotify_df <span class="op">=</span> pd.read_csv(<span class="st">&#39;dataset.csv&#39;</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>spotify_df <span class="op">=</span> spotify_df.drop(columns<span class="op">=</span><span class="st">&#39;Unnamed: 0&#39;</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>spotify_df</span></code></pre></div>
<div class="output execute_result" data-execution_count="4">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>track_id</th>
      <th>artists</th>
      <th>album_name</th>
      <th>track_name</th>
      <th>popularity</th>
      <th>duration_ms</th>
      <th>explicit</th>
      <th>danceability</th>
      <th>energy</th>
      <th>key</th>
      <th>loudness</th>
      <th>mode</th>
      <th>speechiness</th>
      <th>acousticness</th>
      <th>instrumentalness</th>
      <th>liveness</th>
      <th>valence</th>
      <th>tempo</th>
      <th>time_signature</th>
      <th>track_genre</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5SuOikwiRyPMVoIQDJUgSV</td>
      <td>Gen Hoshino</td>
      <td>Comedy</td>
      <td>Comedy</td>
      <td>73</td>
      <td>230666</td>
      <td>False</td>
      <td>0.676</td>
      <td>0.4610</td>
      <td>1</td>
      <td>-6.746</td>
      <td>0</td>
      <td>0.1430</td>
      <td>0.0322</td>
      <td>0.000001</td>
      <td>0.3580</td>
      <td>0.7150</td>
      <td>87.917</td>
      <td>4</td>
      <td>acoustic</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4qPNDBW1i3p13qLCt0Ki3A</td>
      <td>Ben Woodward</td>
      <td>Ghost (Acoustic)</td>
      <td>Ghost - Acoustic</td>
      <td>55</td>
      <td>149610</td>
      <td>False</td>
      <td>0.420</td>
      <td>0.1660</td>
      <td>1</td>
      <td>-17.235</td>
      <td>1</td>
      <td>0.0763</td>
      <td>0.9240</td>
      <td>0.000006</td>
      <td>0.1010</td>
      <td>0.2670</td>
      <td>77.489</td>
      <td>4</td>
      <td>acoustic</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1iJBSr7s7jYXzM8EGcbK5b</td>
      <td>Ingrid Michaelson;ZAYN</td>
      <td>To Begin Again</td>
      <td>To Begin Again</td>
      <td>57</td>
      <td>210826</td>
      <td>False</td>
      <td>0.438</td>
      <td>0.3590</td>
      <td>0</td>
      <td>-9.734</td>
      <td>1</td>
      <td>0.0557</td>
      <td>0.2100</td>
      <td>0.000000</td>
      <td>0.1170</td>
      <td>0.1200</td>
      <td>76.332</td>
      <td>4</td>
      <td>acoustic</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6lfxq3CG4xtTiEg7opyCyx</td>
      <td>Kina Grannis</td>
      <td>Crazy Rich Asians (Original Motion Picture Sou...</td>
      <td>Can't Help Falling In Love</td>
      <td>71</td>
      <td>201933</td>
      <td>False</td>
      <td>0.266</td>
      <td>0.0596</td>
      <td>0</td>
      <td>-18.515</td>
      <td>1</td>
      <td>0.0363</td>
      <td>0.9050</td>
      <td>0.000071</td>
      <td>0.1320</td>
      <td>0.1430</td>
      <td>181.740</td>
      <td>3</td>
      <td>acoustic</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5vjLSffimiIP26QG5WcN2K</td>
      <td>Chord Overstreet</td>
      <td>Hold On</td>
      <td>Hold On</td>
      <td>82</td>
      <td>198853</td>
      <td>False</td>
      <td>0.618</td>
      <td>0.4430</td>
      <td>2</td>
      <td>-9.681</td>
      <td>1</td>
      <td>0.0526</td>
      <td>0.4690</td>
      <td>0.000000</td>
      <td>0.0829</td>
      <td>0.1670</td>
      <td>119.949</td>
      <td>4</td>
      <td>acoustic</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>113995</th>
      <td>2C3TZjDRiAzdyViavDJ217</td>
      <td>Rainy Lullaby</td>
      <td>#mindfulness - Soft Rain for Mindful Meditatio...</td>
      <td>Sleep My Little Boy</td>
      <td>21</td>
      <td>384999</td>
      <td>False</td>
      <td>0.172</td>
      <td>0.2350</td>
      <td>5</td>
      <td>-16.393</td>
      <td>1</td>
      <td>0.0422</td>
      <td>0.6400</td>
      <td>0.928000</td>
      <td>0.0863</td>
      <td>0.0339</td>
      <td>125.995</td>
      <td>5</td>
      <td>world-music</td>
    </tr>
    <tr>
      <th>113996</th>
      <td>1hIz5L4IB9hN3WRYPOCGPw</td>
      <td>Rainy Lullaby</td>
      <td>#mindfulness - Soft Rain for Mindful Meditatio...</td>
      <td>Water Into Light</td>
      <td>22</td>
      <td>385000</td>
      <td>False</td>
      <td>0.174</td>
      <td>0.1170</td>
      <td>0</td>
      <td>-18.318</td>
      <td>0</td>
      <td>0.0401</td>
      <td>0.9940</td>
      <td>0.976000</td>
      <td>0.1050</td>
      <td>0.0350</td>
      <td>85.239</td>
      <td>4</td>
      <td>world-music</td>
    </tr>
    <tr>
      <th>113997</th>
      <td>6x8ZfSoqDjuNa5SVP5QjvX</td>
      <td>Cesária Evora</td>
      <td>Best Of</td>
      <td>Miss Perfumado</td>
      <td>22</td>
      <td>271466</td>
      <td>False</td>
      <td>0.629</td>
      <td>0.3290</td>
      <td>0</td>
      <td>-10.895</td>
      <td>0</td>
      <td>0.0420</td>
      <td>0.8670</td>
      <td>0.000000</td>
      <td>0.0839</td>
      <td>0.7430</td>
      <td>132.378</td>
      <td>4</td>
      <td>world-music</td>
    </tr>
    <tr>
      <th>113998</th>
      <td>2e6sXL2bYv4bSz6VTdnfLs</td>
      <td>Michael W. Smith</td>
      <td>Change Your World</td>
      <td>Friends</td>
      <td>41</td>
      <td>283893</td>
      <td>False</td>
      <td>0.587</td>
      <td>0.5060</td>
      <td>7</td>
      <td>-10.889</td>
      <td>1</td>
      <td>0.0297</td>
      <td>0.3810</td>
      <td>0.000000</td>
      <td>0.2700</td>
      <td>0.4130</td>
      <td>135.960</td>
      <td>4</td>
      <td>world-music</td>
    </tr>
    <tr>
      <th>113999</th>
      <td>2hETkH7cOfqmz3LqZDHZf5</td>
      <td>Cesária Evora</td>
      <td>Miss Perfumado</td>
      <td>Barbincor</td>
      <td>22</td>
      <td>241826</td>
      <td>False</td>
      <td>0.526</td>
      <td>0.4870</td>
      <td>1</td>
      <td>-10.204</td>
      <td>0</td>
      <td>0.0725</td>
      <td>0.6810</td>
      <td>0.000000</td>
      <td>0.0893</td>
      <td>0.7080</td>
      <td>79.198</td>
      <td>4</td>
      <td>world-music</td>
    </tr>
  </tbody>
</table>
<p>114000 rows × 20 columns</p>
</div>
</div>
</div>
<div id="6e2c09cf" class="cell code" data-execution_count="5">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>spotify_df.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="5">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>track_id</th>
      <th>artists</th>
      <th>album_name</th>
      <th>track_name</th>
      <th>popularity</th>
      <th>duration_ms</th>
      <th>explicit</th>
      <th>danceability</th>
      <th>energy</th>
      <th>key</th>
      <th>loudness</th>
      <th>mode</th>
      <th>speechiness</th>
      <th>acousticness</th>
      <th>instrumentalness</th>
      <th>liveness</th>
      <th>valence</th>
      <th>tempo</th>
      <th>time_signature</th>
      <th>track_genre</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5SuOikwiRyPMVoIQDJUgSV</td>
      <td>Gen Hoshino</td>
      <td>Comedy</td>
      <td>Comedy</td>
      <td>73</td>
      <td>230666</td>
      <td>False</td>
      <td>0.676</td>
      <td>0.4610</td>
      <td>1</td>
      <td>-6.746</td>
      <td>0</td>
      <td>0.1430</td>
      <td>0.0322</td>
      <td>0.000001</td>
      <td>0.3580</td>
      <td>0.715</td>
      <td>87.917</td>
      <td>4</td>
      <td>acoustic</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4qPNDBW1i3p13qLCt0Ki3A</td>
      <td>Ben Woodward</td>
      <td>Ghost (Acoustic)</td>
      <td>Ghost - Acoustic</td>
      <td>55</td>
      <td>149610</td>
      <td>False</td>
      <td>0.420</td>
      <td>0.1660</td>
      <td>1</td>
      <td>-17.235</td>
      <td>1</td>
      <td>0.0763</td>
      <td>0.9240</td>
      <td>0.000006</td>
      <td>0.1010</td>
      <td>0.267</td>
      <td>77.489</td>
      <td>4</td>
      <td>acoustic</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1iJBSr7s7jYXzM8EGcbK5b</td>
      <td>Ingrid Michaelson;ZAYN</td>
      <td>To Begin Again</td>
      <td>To Begin Again</td>
      <td>57</td>
      <td>210826</td>
      <td>False</td>
      <td>0.438</td>
      <td>0.3590</td>
      <td>0</td>
      <td>-9.734</td>
      <td>1</td>
      <td>0.0557</td>
      <td>0.2100</td>
      <td>0.000000</td>
      <td>0.1170</td>
      <td>0.120</td>
      <td>76.332</td>
      <td>4</td>
      <td>acoustic</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6lfxq3CG4xtTiEg7opyCyx</td>
      <td>Kina Grannis</td>
      <td>Crazy Rich Asians (Original Motion Picture Sou...</td>
      <td>Can't Help Falling In Love</td>
      <td>71</td>
      <td>201933</td>
      <td>False</td>
      <td>0.266</td>
      <td>0.0596</td>
      <td>0</td>
      <td>-18.515</td>
      <td>1</td>
      <td>0.0363</td>
      <td>0.9050</td>
      <td>0.000071</td>
      <td>0.1320</td>
      <td>0.143</td>
      <td>181.740</td>
      <td>3</td>
      <td>acoustic</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5vjLSffimiIP26QG5WcN2K</td>
      <td>Chord Overstreet</td>
      <td>Hold On</td>
      <td>Hold On</td>
      <td>82</td>
      <td>198853</td>
      <td>False</td>
      <td>0.618</td>
      <td>0.4430</td>
      <td>2</td>
      <td>-9.681</td>
      <td>1</td>
      <td>0.0526</td>
      <td>0.4690</td>
      <td>0.000000</td>
      <td>0.0829</td>
      <td>0.167</td>
      <td>119.949</td>
      <td>4</td>
      <td>acoustic</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div id="1b064d40" class="cell markdown">
<p>Let's learn more about the data! How many samples, features, data
types, etc...</p>
</div>
<div id="32d477c7" class="cell code" data-execution_count="6">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Number of samples:&#39;</span>, spotify_df.shape[<span class="dv">0</span>])</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Number of features:&#39;</span>, spotify_df.shape[<span class="dv">1</span>])</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Category Data Types:</span><span class="ch">\n</span><span class="sc">{</span>spotify_df<span class="sc">.</span>dtypes<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating a list with all category names.</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>categories <span class="op">=</span> spotify_df.columns.tolist()[<span class="dv">1</span>:]</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Categories:&quot;</span>, categories)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Number of samples: 114000
Number of features: 20
Category Data Types:
track_id             object
artists              object
album_name           object
track_name           object
popularity            int64
duration_ms           int64
explicit               bool
danceability        float64
energy              float64
key                   int64
loudness            float64
mode                  int64
speechiness         float64
acousticness        float64
instrumentalness    float64
liveness            float64
valence             float64
tempo               float64
time_signature        int64
track_genre          object
dtype: object
Categories: [&#39;artists&#39;, &#39;album_name&#39;, &#39;track_name&#39;, &#39;popularity&#39;, &#39;duration_ms&#39;, &#39;explicit&#39;, &#39;danceability&#39;, &#39;energy&#39;, &#39;key&#39;, &#39;loudness&#39;, &#39;mode&#39;, &#39;speechiness&#39;, &#39;acousticness&#39;, &#39;instrumentalness&#39;, &#39;liveness&#39;, &#39;valence&#39;, &#39;tempo&#39;, &#39;time_signature&#39;, &#39;track_genre&#39;]
</code></pre>
</div>
</div>
<div id="1e81a93d" class="cell markdown">
<p>Now let's look if there are any missing values!</p>
</div>
<div id="ee40d41e" class="cell code" data-execution_count="7">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>missing_data <span class="op">=</span> spotify_df.isna().<span class="bu">sum</span>()</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(missing_data)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Saving missing values as dictionary as missing values for each category.</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>missing_data <span class="op">=</span> missing_data.to_dict()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>track_id            0
artists             1
album_name          1
track_name          1
popularity          0
duration_ms         0
explicit            0
danceability        0
energy              0
key                 0
loudness            0
mode                0
speechiness         0
acousticness        0
instrumentalness    0
liveness            0
valence             0
tempo               0
time_signature      0
track_genre         0
dtype: int64
</code></pre>
</div>
</div>
<div id="60dcba4b" class="cell code" data-execution_count="8">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Just making sure the count is the same for each column</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>spotify_df.count()</span></code></pre></div>
<div class="output execute_result" data-execution_count="8">
<pre><code>track_id            114000
artists             113999
album_name          113999
track_name          113999
popularity          114000
duration_ms         114000
explicit            114000
danceability        114000
energy              114000
key                 114000
loudness            114000
mode                114000
speechiness         114000
acousticness        114000
instrumentalness    114000
liveness            114000
valence             114000
tempo               114000
time_signature      114000
track_genre         114000
dtype: int64</code></pre>
</div>
</div>
<div id="850f35d2" class="cell markdown">
<p>Looks like there is 1 missing value each in the artists, album_name,
and track_name categories. Since <br> the proportion of missing data is
&lt;5% we can use Listwise Deletion to get rid of the missing
values.</p>
</div>
<div id="72f8547d" class="cell code" data-execution_count="9">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Dropping the row with NA values in the dataframe.</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>spotify_df <span class="op">=</span> spotify_df.dropna()</span></code></pre></div>
</div>
<div id="6b9d5e9c" class="cell markdown">
<p>Now check for duplicate values in the dataset.</p>
</div>
<div id="a1e77f79" class="cell code" data-execution_count="10">
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>duplicates <span class="op">=</span> spotify_df[spotify_df.duplicated()]</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(duplicates)</span></code></pre></div>
<div class="output execute_result" data-execution_count="10">
<pre><code>450</code></pre>
</div>
</div>
<div id="34c56b40" class="cell markdown">
<p>Looks like there are 450 rows with exact duplicates in the dataset
that need to be removed.</p>
</div>
<div id="a181b0eb" class="cell code" data-execution_count="11">
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>spotify_df[<span class="st">&#39;track_id&#39;</span>].duplicated(keep<span class="op">=</span><span class="va">False</span>).<span class="bu">sum</span>()</span></code></pre></div>
<div class="output execute_result" data-execution_count="11">
<pre><code>40900</code></pre>
</div>
</div>
<div id="addf81ea" class="cell code" data-execution_count="12">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>duplicated_ids <span class="op">=</span> spotify_df[<span class="st">&#39;track_id&#39;</span>].value_counts()</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>duplicated_ids <span class="op">=</span> duplicated_ids[duplicated_ids <span class="op">&gt;</span> <span class="dv">1</span>]</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>duplicated_ids</span></code></pre></div>
<div class="output execute_result" data-execution_count="12">
<pre><code>track_id
6S3JlDAGk3uu3NtZbPnuhS    9
2Ey6v4Sekh3Z0RUSISRosD    8
2kkvB3RNRzwjFdGhaUA0tz    8
08kTa3SL9sV6Iy8KLKtGql    7
4XYieGKSlJlHpzB3bl6WMP    7
                         ..
2K6jJQ1i2SVNWLEF06Ha4B    2
0hjpo40L9XPirSdaJZOGB2    2
40XeGNGFchGYw7y0ue1GiG    2
50xwQXPtfNZFKFeZ0XePWc    2
6NDoBIaqTHdcudaR8RDJNw    2
Name: count, Length: 16641, dtype: int64</code></pre>
</div>
</div>
<div id="ee095351" class="cell markdown">
<p>Digging further it can be seen that there are 16,641 tracks that are
listed multiple times in the dataset since they fall under multiple
genres. This information can come in handy later during model
creation.</p>
</div>
<div id="cdc3afe5" class="cell code" data-execution_count="13">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Removing the exact duplicates from the dataset</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>spotify_df <span class="op">=</span> spotify_df.drop_duplicates()</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>spotify_df.duplicated().<span class="bu">sum</span>()</span></code></pre></div>
<div class="output execute_result" data-execution_count="13">
<pre><code>0</code></pre>
</div>
</div>
<div id="f3707853" class="cell markdown">
<p>The category, track_genre, is currently a string (object) describing
what the genre of the particular song is. <br> We need to convert this
to numeric values through feature encoding for our model to use later
on.</p>
</div>
<div id="bb0a912b" class="cell code" data-execution_count="14">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Checking cardinality to see what type of encoding would best fit this scenario.</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(spotify_df[<span class="st">&#39;track_genre&#39;</span>].nunique())</span></code></pre></div>
<div class="output stream stdout">
<pre><code>114
</code></pre>
</div>
</div>
<div id="20a53e7b" class="cell markdown">
<p>Since this category has a high cardinality, one hot encoding would
create too many new columns. <br> Let's try using frequency encoding
here to convert this column.</p>
</div>
<div id="29a75ba0" class="cell code" data-execution_count="15">
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>freq_encoding <span class="op">=</span> spotify_df[<span class="st">&#39;track_genre&#39;</span>].value_counts()</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>spotify_df[<span class="st">&#39;track_genre_freq&#39;</span>] <span class="op">=</span> spotify_df[<span class="st">&#39;track_genre&#39;</span>].<span class="bu">map</span>(freq_encoding)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>spotify_df</span></code></pre></div>
<div class="output execute_result" data-execution_count="15">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>track_id</th>
      <th>artists</th>
      <th>album_name</th>
      <th>track_name</th>
      <th>popularity</th>
      <th>duration_ms</th>
      <th>explicit</th>
      <th>danceability</th>
      <th>energy</th>
      <th>key</th>
      <th>...</th>
      <th>mode</th>
      <th>speechiness</th>
      <th>acousticness</th>
      <th>instrumentalness</th>
      <th>liveness</th>
      <th>valence</th>
      <th>tempo</th>
      <th>time_signature</th>
      <th>track_genre</th>
      <th>track_genre_freq</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5SuOikwiRyPMVoIQDJUgSV</td>
      <td>Gen Hoshino</td>
      <td>Comedy</td>
      <td>Comedy</td>
      <td>73</td>
      <td>230666</td>
      <td>False</td>
      <td>0.676</td>
      <td>0.4610</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0.1430</td>
      <td>0.0322</td>
      <td>0.000001</td>
      <td>0.3580</td>
      <td>0.7150</td>
      <td>87.917</td>
      <td>4</td>
      <td>acoustic</td>
      <td>1000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4qPNDBW1i3p13qLCt0Ki3A</td>
      <td>Ben Woodward</td>
      <td>Ghost (Acoustic)</td>
      <td>Ghost - Acoustic</td>
      <td>55</td>
      <td>149610</td>
      <td>False</td>
      <td>0.420</td>
      <td>0.1660</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>0.0763</td>
      <td>0.9240</td>
      <td>0.000006</td>
      <td>0.1010</td>
      <td>0.2670</td>
      <td>77.489</td>
      <td>4</td>
      <td>acoustic</td>
      <td>1000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1iJBSr7s7jYXzM8EGcbK5b</td>
      <td>Ingrid Michaelson;ZAYN</td>
      <td>To Begin Again</td>
      <td>To Begin Again</td>
      <td>57</td>
      <td>210826</td>
      <td>False</td>
      <td>0.438</td>
      <td>0.3590</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0.0557</td>
      <td>0.2100</td>
      <td>0.000000</td>
      <td>0.1170</td>
      <td>0.1200</td>
      <td>76.332</td>
      <td>4</td>
      <td>acoustic</td>
      <td>1000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6lfxq3CG4xtTiEg7opyCyx</td>
      <td>Kina Grannis</td>
      <td>Crazy Rich Asians (Original Motion Picture Sou...</td>
      <td>Can't Help Falling In Love</td>
      <td>71</td>
      <td>201933</td>
      <td>False</td>
      <td>0.266</td>
      <td>0.0596</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0.0363</td>
      <td>0.9050</td>
      <td>0.000071</td>
      <td>0.1320</td>
      <td>0.1430</td>
      <td>181.740</td>
      <td>3</td>
      <td>acoustic</td>
      <td>1000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5vjLSffimiIP26QG5WcN2K</td>
      <td>Chord Overstreet</td>
      <td>Hold On</td>
      <td>Hold On</td>
      <td>82</td>
      <td>198853</td>
      <td>False</td>
      <td>0.618</td>
      <td>0.4430</td>
      <td>2</td>
      <td>...</td>
      <td>1</td>
      <td>0.0526</td>
      <td>0.4690</td>
      <td>0.000000</td>
      <td>0.0829</td>
      <td>0.1670</td>
      <td>119.949</td>
      <td>4</td>
      <td>acoustic</td>
      <td>1000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>113995</th>
      <td>2C3TZjDRiAzdyViavDJ217</td>
      <td>Rainy Lullaby</td>
      <td>#mindfulness - Soft Rain for Mindful Meditatio...</td>
      <td>Sleep My Little Boy</td>
      <td>21</td>
      <td>384999</td>
      <td>False</td>
      <td>0.172</td>
      <td>0.2350</td>
      <td>5</td>
      <td>...</td>
      <td>1</td>
      <td>0.0422</td>
      <td>0.6400</td>
      <td>0.928000</td>
      <td>0.0863</td>
      <td>0.0339</td>
      <td>125.995</td>
      <td>5</td>
      <td>world-music</td>
      <td>999</td>
    </tr>
    <tr>
      <th>113996</th>
      <td>1hIz5L4IB9hN3WRYPOCGPw</td>
      <td>Rainy Lullaby</td>
      <td>#mindfulness - Soft Rain for Mindful Meditatio...</td>
      <td>Water Into Light</td>
      <td>22</td>
      <td>385000</td>
      <td>False</td>
      <td>0.174</td>
      <td>0.1170</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0.0401</td>
      <td>0.9940</td>
      <td>0.976000</td>
      <td>0.1050</td>
      <td>0.0350</td>
      <td>85.239</td>
      <td>4</td>
      <td>world-music</td>
      <td>999</td>
    </tr>
    <tr>
      <th>113997</th>
      <td>6x8ZfSoqDjuNa5SVP5QjvX</td>
      <td>Cesária Evora</td>
      <td>Best Of</td>
      <td>Miss Perfumado</td>
      <td>22</td>
      <td>271466</td>
      <td>False</td>
      <td>0.629</td>
      <td>0.3290</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0.0420</td>
      <td>0.8670</td>
      <td>0.000000</td>
      <td>0.0839</td>
      <td>0.7430</td>
      <td>132.378</td>
      <td>4</td>
      <td>world-music</td>
      <td>999</td>
    </tr>
    <tr>
      <th>113998</th>
      <td>2e6sXL2bYv4bSz6VTdnfLs</td>
      <td>Michael W. Smith</td>
      <td>Change Your World</td>
      <td>Friends</td>
      <td>41</td>
      <td>283893</td>
      <td>False</td>
      <td>0.587</td>
      <td>0.5060</td>
      <td>7</td>
      <td>...</td>
      <td>1</td>
      <td>0.0297</td>
      <td>0.3810</td>
      <td>0.000000</td>
      <td>0.2700</td>
      <td>0.4130</td>
      <td>135.960</td>
      <td>4</td>
      <td>world-music</td>
      <td>999</td>
    </tr>
    <tr>
      <th>113999</th>
      <td>2hETkH7cOfqmz3LqZDHZf5</td>
      <td>Cesária Evora</td>
      <td>Miss Perfumado</td>
      <td>Barbincor</td>
      <td>22</td>
      <td>241826</td>
      <td>False</td>
      <td>0.526</td>
      <td>0.4870</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0.0725</td>
      <td>0.6810</td>
      <td>0.000000</td>
      <td>0.0893</td>
      <td>0.7080</td>
      <td>79.198</td>
      <td>4</td>
      <td>world-music</td>
      <td>999</td>
    </tr>
  </tbody>
</table>
<p>113549 rows × 21 columns</p>
</div>
</div>
</div>
<div id="708cacfb" class="cell code" data-execution_count="16">
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>spotify_df[<span class="st">&#39;track_genre_freq&#39;</span>].unique()</span></code></pre></div>
<div class="output execute_result" data-execution_count="16">
<pre><code>array([1000,  999,  997,  998,  933,  995,  996,  965,  993,  963,  991,
        981,  988,  990,  994,  992,  904], dtype=int64)</code></pre>
</div>
</div>
<div id="3bbf31ee" class="cell markdown">
<p>Looks like frequency encoding might not be the best option since
looks the frequency of the genres are 999 or 1000 which loses much of
the uniqueness and information we are looking for from this category.
Another good option for encoding when there is high cardinality is
Target/Mean Encoding, let's try that!</p>
</div>
<div id="b0a7f4e1" class="cell code" data-execution_count="17">
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>genre_popularity_map <span class="op">=</span> spotify_df.groupby(<span class="st">&#39;track_genre&#39;</span>)[<span class="st">&#39;popularity&#39;</span>].mean()</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>spotify_df[<span class="st">&#39;track_genre_target_enc&#39;</span>] <span class="op">=</span> spotify_df[<span class="st">&#39;track_genre&#39;</span>].<span class="bu">map</span>(genre_popularity_map)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;No. Unique Values: &#39;</span>, spotify_df[<span class="st">&#39;track_genre_target_enc&#39;</span>].nunique())</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>spotify_df</span></code></pre></div>
<div class="output stream stdout">
<pre><code>No. Unique Values:  113
</code></pre>
</div>
<div class="output execute_result" data-execution_count="17">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>track_id</th>
      <th>artists</th>
      <th>album_name</th>
      <th>track_name</th>
      <th>popularity</th>
      <th>duration_ms</th>
      <th>explicit</th>
      <th>danceability</th>
      <th>energy</th>
      <th>key</th>
      <th>...</th>
      <th>speechiness</th>
      <th>acousticness</th>
      <th>instrumentalness</th>
      <th>liveness</th>
      <th>valence</th>
      <th>tempo</th>
      <th>time_signature</th>
      <th>track_genre</th>
      <th>track_genre_freq</th>
      <th>track_genre_target_enc</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5SuOikwiRyPMVoIQDJUgSV</td>
      <td>Gen Hoshino</td>
      <td>Comedy</td>
      <td>Comedy</td>
      <td>73</td>
      <td>230666</td>
      <td>False</td>
      <td>0.676</td>
      <td>0.4610</td>
      <td>1</td>
      <td>...</td>
      <td>0.1430</td>
      <td>0.0322</td>
      <td>0.000001</td>
      <td>0.3580</td>
      <td>0.7150</td>
      <td>87.917</td>
      <td>4</td>
      <td>acoustic</td>
      <td>1000</td>
      <td>42.483000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4qPNDBW1i3p13qLCt0Ki3A</td>
      <td>Ben Woodward</td>
      <td>Ghost (Acoustic)</td>
      <td>Ghost - Acoustic</td>
      <td>55</td>
      <td>149610</td>
      <td>False</td>
      <td>0.420</td>
      <td>0.1660</td>
      <td>1</td>
      <td>...</td>
      <td>0.0763</td>
      <td>0.9240</td>
      <td>0.000006</td>
      <td>0.1010</td>
      <td>0.2670</td>
      <td>77.489</td>
      <td>4</td>
      <td>acoustic</td>
      <td>1000</td>
      <td>42.483000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1iJBSr7s7jYXzM8EGcbK5b</td>
      <td>Ingrid Michaelson;ZAYN</td>
      <td>To Begin Again</td>
      <td>To Begin Again</td>
      <td>57</td>
      <td>210826</td>
      <td>False</td>
      <td>0.438</td>
      <td>0.3590</td>
      <td>0</td>
      <td>...</td>
      <td>0.0557</td>
      <td>0.2100</td>
      <td>0.000000</td>
      <td>0.1170</td>
      <td>0.1200</td>
      <td>76.332</td>
      <td>4</td>
      <td>acoustic</td>
      <td>1000</td>
      <td>42.483000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6lfxq3CG4xtTiEg7opyCyx</td>
      <td>Kina Grannis</td>
      <td>Crazy Rich Asians (Original Motion Picture Sou...</td>
      <td>Can't Help Falling In Love</td>
      <td>71</td>
      <td>201933</td>
      <td>False</td>
      <td>0.266</td>
      <td>0.0596</td>
      <td>0</td>
      <td>...</td>
      <td>0.0363</td>
      <td>0.9050</td>
      <td>0.000071</td>
      <td>0.1320</td>
      <td>0.1430</td>
      <td>181.740</td>
      <td>3</td>
      <td>acoustic</td>
      <td>1000</td>
      <td>42.483000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5vjLSffimiIP26QG5WcN2K</td>
      <td>Chord Overstreet</td>
      <td>Hold On</td>
      <td>Hold On</td>
      <td>82</td>
      <td>198853</td>
      <td>False</td>
      <td>0.618</td>
      <td>0.4430</td>
      <td>2</td>
      <td>...</td>
      <td>0.0526</td>
      <td>0.4690</td>
      <td>0.000000</td>
      <td>0.0829</td>
      <td>0.1670</td>
      <td>119.949</td>
      <td>4</td>
      <td>acoustic</td>
      <td>1000</td>
      <td>42.483000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>113995</th>
      <td>2C3TZjDRiAzdyViavDJ217</td>
      <td>Rainy Lullaby</td>
      <td>#mindfulness - Soft Rain for Mindful Meditatio...</td>
      <td>Sleep My Little Boy</td>
      <td>21</td>
      <td>384999</td>
      <td>False</td>
      <td>0.172</td>
      <td>0.2350</td>
      <td>5</td>
      <td>...</td>
      <td>0.0422</td>
      <td>0.6400</td>
      <td>0.928000</td>
      <td>0.0863</td>
      <td>0.0339</td>
      <td>125.995</td>
      <td>5</td>
      <td>world-music</td>
      <td>999</td>
      <td>41.880881</td>
    </tr>
    <tr>
      <th>113996</th>
      <td>1hIz5L4IB9hN3WRYPOCGPw</td>
      <td>Rainy Lullaby</td>
      <td>#mindfulness - Soft Rain for Mindful Meditatio...</td>
      <td>Water Into Light</td>
      <td>22</td>
      <td>385000</td>
      <td>False</td>
      <td>0.174</td>
      <td>0.1170</td>
      <td>0</td>
      <td>...</td>
      <td>0.0401</td>
      <td>0.9940</td>
      <td>0.976000</td>
      <td>0.1050</td>
      <td>0.0350</td>
      <td>85.239</td>
      <td>4</td>
      <td>world-music</td>
      <td>999</td>
      <td>41.880881</td>
    </tr>
    <tr>
      <th>113997</th>
      <td>6x8ZfSoqDjuNa5SVP5QjvX</td>
      <td>Cesária Evora</td>
      <td>Best Of</td>
      <td>Miss Perfumado</td>
      <td>22</td>
      <td>271466</td>
      <td>False</td>
      <td>0.629</td>
      <td>0.3290</td>
      <td>0</td>
      <td>...</td>
      <td>0.0420</td>
      <td>0.8670</td>
      <td>0.000000</td>
      <td>0.0839</td>
      <td>0.7430</td>
      <td>132.378</td>
      <td>4</td>
      <td>world-music</td>
      <td>999</td>
      <td>41.880881</td>
    </tr>
    <tr>
      <th>113998</th>
      <td>2e6sXL2bYv4bSz6VTdnfLs</td>
      <td>Michael W. Smith</td>
      <td>Change Your World</td>
      <td>Friends</td>
      <td>41</td>
      <td>283893</td>
      <td>False</td>
      <td>0.587</td>
      <td>0.5060</td>
      <td>7</td>
      <td>...</td>
      <td>0.0297</td>
      <td>0.3810</td>
      <td>0.000000</td>
      <td>0.2700</td>
      <td>0.4130</td>
      <td>135.960</td>
      <td>4</td>
      <td>world-music</td>
      <td>999</td>
      <td>41.880881</td>
    </tr>
    <tr>
      <th>113999</th>
      <td>2hETkH7cOfqmz3LqZDHZf5</td>
      <td>Cesária Evora</td>
      <td>Miss Perfumado</td>
      <td>Barbincor</td>
      <td>22</td>
      <td>241826</td>
      <td>False</td>
      <td>0.526</td>
      <td>0.4870</td>
      <td>1</td>
      <td>...</td>
      <td>0.0725</td>
      <td>0.6810</td>
      <td>0.000000</td>
      <td>0.0893</td>
      <td>0.7080</td>
      <td>79.198</td>
      <td>4</td>
      <td>world-music</td>
      <td>999</td>
      <td>41.880881</td>
    </tr>
  </tbody>
</table>
<p>113549 rows × 22 columns</p>
</div>
</div>
</div>
<div id="c28af126" class="cell markdown">
<h2 id="iii-exploratory-data-analysis">III. Exploratory Data
Analysis</h2>
</div>
<div id="6b9ec109" class="cell markdown">
<h3 id="-q1-correlations">🎯 Q1: Correlations</h3>
<p>We will start our analysis by determining how each feature is related
to each other. To do this, we will create a plot of the correlations
between each numerical feature.</p>
</div>
<div id="c048a6f4" class="cell code" data-execution_count="36">
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Credit: https://www.geeksforgeeks.org/data-analysis/exploring-correlation-in-python/</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>corr <span class="op">=</span> spotify_df.corr(method <span class="op">=</span> <span class="st">&#39;pearson&#39;</span>, numeric_only<span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">8</span>), dpi <span class="op">=</span><span class="dv">500</span>)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Correlations between Features&quot;</span>)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> sns.heatmap(corr,annot<span class="op">=</span><span class="va">True</span>,fmt<span class="op">=</span><span class="st">&quot;.2f&quot;</span>, linewidth<span class="op">=</span><span class="fl">.5</span>)</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">&quot;Features&quot;</span>)</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">&quot;Features&quot;</span>)</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/4aee0cc5f7f981aa7f0df113861da6c1d49e6ca4.png" /></p>
</div>
</div>
<div id="29b71c34" class="cell markdown">
<p>We can see from the above plot that some features are more
correlated, such as acousticness and energy, as well as acousticness and
loudness. However, most features are not highly correlated. This is
easier to see when we plot the absolute value of the correlation.</p>
</div>
<div id="f5bccfd5" class="cell code" data-execution_count="37">
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">8</span>), dpi <span class="op">=</span><span class="dv">500</span>)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Correlations between Features&quot;</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> sns.heatmap(corr.<span class="bu">abs</span>(),annot<span class="op">=</span><span class="va">True</span>,fmt<span class="op">=</span><span class="st">&quot;.2f&quot;</span>, linewidth<span class="op">=</span><span class="fl">.5</span>)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">&quot;Features&quot;</span>)</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">&quot;Features&quot;</span>)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/02f03ee7a80138facc950d42afb0551738fadbec.png" /></p>
</div>
</div>
<div id="e3e217c2" class="cell markdown">
<p>Most of the pairs of features have absolute correlation less than
0.1. To expand on this, let's find out which features are most
correlated to which.</p>
</div>
<div id="b65e22f4" class="cell code" data-execution_count="38">
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>pairs <span class="op">=</span> <span class="bu">list</span>()</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> column <span class="kw">in</span> corr.columns:</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    related_feature <span class="op">=</span> corr[column].<span class="bu">abs</span>().sort_values(ascending<span class="op">=</span> <span class="va">False</span>).iloc[[<span class="dv">1</span>]].index.array[<span class="dv">0</span>]</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    pairs.append([column, related_feature])</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(column, <span class="st">&quot; is most correlated with &quot;</span>, related_feature)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>popularity  is most correlated with  track_genre_target_enc
duration_ms  is most correlated with  valence
explicit  is most correlated with  speechiness
danceability  is most correlated with  valence
energy  is most correlated with  loudness
key  is most correlated with  mode
loudness  is most correlated with  energy
mode  is most correlated with  key
speechiness  is most correlated with  explicit
acousticness  is most correlated with  energy
instrumentalness  is most correlated with  loudness
liveness  is most correlated with  speechiness
valence  is most correlated with  danceability
tempo  is most correlated with  energy
time_signature  is most correlated with  danceability
track_genre_freq  is most correlated with  track_genre_target_enc
track_genre_target_enc  is most correlated with  popularity
</code></pre>
</div>
</div>
<div id="a499d949" class="cell markdown">
<p>Some interesting points come from this:</p>
<ul>
<li>the duration of a song tends to be longer when the valence ("musical
positiveness") is lower,</li>
<li>in contrast the danceability tends to be higher when the valence is
higher,</li>
<li>energy (intensity) is highly correlated with loudness and
acousticness,</li>
<li>the tempo tends to be faster when the energy is higher.</li>
</ul>
<p>Above all however, is that popularity is not highly correlated with
any feature except for potentially track genre.</p>
</div>
<div id="83a63647" class="cell markdown">
<h3 id="-q2-is-popularity-related-to-genrekey">🎯 Q2: Is popularity
related to genre/key?</h3>
<p>🔬 Statistical Method: One-way ANOVA (Analysis of Variance)</p>
</div>
<div id="f875cbef" class="cell code" data-execution_count="39">
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a list of popularity scores per genre</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>genre_groups <span class="op">=</span> [group[<span class="st">&#39;popularity&#39;</span>].values <span class="cf">for</span> name, group <span class="kw">in</span> spotify_df.groupby(<span class="st">&#39;track_genre&#39;</span>)]</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>F <span class="op">=</span> f_oneway(<span class="op">*</span>genre_groups)</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;P-Value received from the ANOVA-testing&quot;</span>, F.pvalue)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>P-Value received from the ANOVA-testing 0.0
</code></pre>
</div>
</div>
<div id="107d067c" class="cell markdown">
<p>This p-value tells us that there is there is strong evidence that at
<em>least one genre</em> has a different mean popularity compared to the
others since it is &lt;0.05</p>
</div>
<div id="4263b813" class="cell markdown">
<p>From doing the ANOVA test, we can only learn that there is a
significant difference between the means of the groups included. Now to
find out which one of these groups differ, we must do a Post Hoc Test
such as Tukey's Honest Significant Difference (HSD). Here I will do the
HSD test on the 10 most popular genre's since doing this test on 114
genres will become overwhelming.</p>
</div>
<div id="434f5bea" class="cell code" data-execution_count="40">
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Find top 10 genres by mean popularity</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>top_10_popular_genres <span class="op">=</span> (</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>    spotify_df.groupby(<span class="st">&#39;track_genre&#39;</span>)[<span class="st">&#39;popularity&#39;</span>]</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>    .mean()</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>    .sort_values(ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>    .head(<span class="dv">10</span>)</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>    .index</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter dataframe</span></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>df_top10 <span class="op">=</span> spotify_df[spotify_df[<span class="st">&#39;track_genre&#39;</span>].isin(top_10_popular_genres)]</span></code></pre></div>
</div>
<div id="cd0a8efa" class="cell code" data-execution_count="41">
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert popularity values into a list per genre</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>groups <span class="op">=</span> [df_top10[df_top10[<span class="st">&#39;track_genre&#39;</span>] <span class="op">==</span> genre][<span class="st">&#39;popularity&#39;</span>].values</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>          <span class="cf">for</span> genre <span class="kw">in</span> top_10_popular_genres]</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Run Tukey HSD</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> tukey_hsd(<span class="op">*</span>groups)</span></code></pre></div>
</div>
<div id="eb1f0459" class="cell markdown">
<p>We are going to make the result of the HSD into a pandas dataframe to
make it easier to view.</p>
</div>
<div id="3c6249a7" class="cell code" data-execution_count="42">
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>genre_list <span class="op">=</span> <span class="bu">list</span>(top_10_popular_genres)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>comparisons <span class="op">=</span> []</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i, j), stat <span class="kw">in</span> np.ndenumerate(res.statistic):</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> i <span class="op">&lt;</span> j:</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>        comparisons.append({</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;Genre A&#39;</span>: genre_list[i],</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;Genre B&#39;</span>: genre_list[j],</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;Mean Diff&#39;</span>: stat,</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;p-value&#39;</span>: res.pvalue[i, j],</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;Lower CI&#39;</span>: res.confidence_interval().low[i, j],</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;Upper CI&#39;</span>: res.confidence_interval().high[i, j],</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;Significant&#39;</span>: res.pvalue[i, j] <span class="op">&lt;</span> <span class="fl">0.05</span></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to DataFrame</span></span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>tukey_df <span class="op">=</span> pd.DataFrame(comparisons)</span></code></pre></div>
</div>
<div id="a04a4c11" class="cell code" data-execution_count="43">
<div class="sourceCode" id="cb35"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>tukey_df <span class="op">=</span>  tukey_df.sort_values(by<span class="op">=</span><span class="st">&#39;p-value&#39;</span>)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>tukey_df</span></code></pre></div>
<div class="output execute_result" data-execution_count="43">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Genre A</th>
      <th>Genre B</th>
      <th>Mean Diff</th>
      <th>p-value</th>
      <th>Lower CI</th>
      <th>Upper CI</th>
      <th>Significant</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>22</th>
      <td>chill</td>
      <td>pop</td>
      <td>5.801381</td>
      <td>0.000000e+00</td>
      <td>3.418556</td>
      <td>8.184207</td>
      <td>True</td>
    </tr>
    <tr>
      <th>23</th>
      <td>chill</td>
      <td>sertanejo</td>
      <td>5.838705</td>
      <td>0.000000e+00</td>
      <td>3.460066</td>
      <td>8.217344</td>
      <td>True</td>
    </tr>
    <tr>
      <th>16</th>
      <td>k-pop</td>
      <td>sertanejo</td>
      <td>9.097928</td>
      <td>0.000000e+00</td>
      <td>6.718693</td>
      <td>11.477163</td>
      <td>True</td>
    </tr>
    <tr>
      <th>15</th>
      <td>k-pop</td>
      <td>pop</td>
      <td>9.060605</td>
      <td>0.000000e+00</td>
      <td>6.677184</td>
      <td>11.444025</td>
      <td>True</td>
    </tr>
    <tr>
      <th>14</th>
      <td>k-pop</td>
      <td>emo</td>
      <td>8.835928</td>
      <td>0.000000e+00</td>
      <td>6.456693</td>
      <td>11.215163</td>
      <td>True</td>
    </tr>
    <tr>
      <th>12</th>
      <td>k-pop</td>
      <td>indian</td>
      <td>7.435399</td>
      <td>0.000000e+00</td>
      <td>5.055569</td>
      <td>9.815229</td>
      <td>True</td>
    </tr>
    <tr>
      <th>11</th>
      <td>k-pop</td>
      <td>grunge</td>
      <td>7.381345</td>
      <td>0.000000e+00</td>
      <td>5.001515</td>
      <td>9.761175</td>
      <td>True</td>
    </tr>
    <tr>
      <th>8</th>
      <td>pop-film</td>
      <td>sertanejo</td>
      <td>11.414280</td>
      <td>0.000000e+00</td>
      <td>9.035641</td>
      <td>13.792919</td>
      <td>True</td>
    </tr>
    <tr>
      <th>13</th>
      <td>k-pop</td>
      <td>anime</td>
      <td>8.197161</td>
      <td>0.000000e+00</td>
      <td>5.817331</td>
      <td>10.576991</td>
      <td>True</td>
    </tr>
    <tr>
      <th>6</th>
      <td>pop-film</td>
      <td>emo</td>
      <td>11.152280</td>
      <td>0.000000e+00</td>
      <td>8.773641</td>
      <td>13.530919</td>
      <td>True</td>
    </tr>
    <tr>
      <th>5</th>
      <td>pop-film</td>
      <td>anime</td>
      <td>10.513514</td>
      <td>0.000000e+00</td>
      <td>8.134280</td>
      <td>12.892747</td>
      <td>True</td>
    </tr>
    <tr>
      <th>4</th>
      <td>pop-film</td>
      <td>indian</td>
      <td>9.751752</td>
      <td>0.000000e+00</td>
      <td>7.372518</td>
      <td>12.130986</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>pop-film</td>
      <td>grunge</td>
      <td>9.697698</td>
      <td>0.000000e+00</td>
      <td>7.318464</td>
      <td>12.076932</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>pop-film</td>
      <td>sad</td>
      <td>6.901280</td>
      <td>0.000000e+00</td>
      <td>4.522641</td>
      <td>9.279919</td>
      <td>True</td>
    </tr>
    <tr>
      <th>7</th>
      <td>pop-film</td>
      <td>pop</td>
      <td>11.376957</td>
      <td>0.000000e+00</td>
      <td>8.994132</td>
      <td>13.759782</td>
      <td>True</td>
    </tr>
    <tr>
      <th>21</th>
      <td>chill</td>
      <td>emo</td>
      <td>5.576705</td>
      <td>4.717338e-12</td>
      <td>3.198066</td>
      <td>7.955344</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>pop-film</td>
      <td>chill</td>
      <td>5.575576</td>
      <td>4.863887e-12</td>
      <td>3.196342</td>
      <td>7.954810</td>
      <td>True</td>
    </tr>
    <tr>
      <th>20</th>
      <td>chill</td>
      <td>anime</td>
      <td>4.937938</td>
      <td>2.413916e-09</td>
      <td>2.558704</td>
      <td>7.317172</td>
      <td>True</td>
    </tr>
    <tr>
      <th>10</th>
      <td>k-pop</td>
      <td>sad</td>
      <td>4.584928</td>
      <td>4.999529e-08</td>
      <td>2.205693</td>
      <td>6.964163</td>
      <td>True</td>
    </tr>
    <tr>
      <th>29</th>
      <td>sad</td>
      <td>sertanejo</td>
      <td>4.513000</td>
      <td>8.863988e-08</td>
      <td>2.134956</td>
      <td>6.891044</td>
      <td>True</td>
    </tr>
    <tr>
      <th>28</th>
      <td>sad</td>
      <td>pop</td>
      <td>4.475677</td>
      <td>1.279613e-07</td>
      <td>2.093445</td>
      <td>6.857908</td>
      <td>True</td>
    </tr>
    <tr>
      <th>27</th>
      <td>sad</td>
      <td>emo</td>
      <td>4.251000</td>
      <td>7.089971e-07</td>
      <td>1.872956</td>
      <td>6.629044</td>
      <td>True</td>
    </tr>
    <tr>
      <th>19</th>
      <td>chill</td>
      <td>indian</td>
      <td>4.176176</td>
      <td>1.276040e-06</td>
      <td>1.796942</td>
      <td>6.555410</td>
      <td>True</td>
    </tr>
    <tr>
      <th>18</th>
      <td>chill</td>
      <td>grunge</td>
      <td>4.122122</td>
      <td>1.916241e-06</td>
      <td>1.742888</td>
      <td>6.501356</td>
      <td>True</td>
    </tr>
    <tr>
      <th>26</th>
      <td>sad</td>
      <td>anime</td>
      <td>3.612233</td>
      <td>6.834448e-05</td>
      <td>1.233594</td>
      <td>5.990872</td>
      <td>True</td>
    </tr>
    <tr>
      <th>9</th>
      <td>k-pop</td>
      <td>chill</td>
      <td>3.259223</td>
      <td>6.234850e-04</td>
      <td>0.879393</td>
      <td>5.639053</td>
      <td>True</td>
    </tr>
    <tr>
      <th>25</th>
      <td>sad</td>
      <td>indian</td>
      <td>2.850471</td>
      <td>5.832857e-03</td>
      <td>0.471832</td>
      <td>5.229111</td>
      <td>True</td>
    </tr>
    <tr>
      <th>24</th>
      <td>sad</td>
      <td>grunge</td>
      <td>2.796417</td>
      <td>7.650167e-03</td>
      <td>0.417778</td>
      <td>5.175057</td>
      <td>True</td>
    </tr>
    <tr>
      <th>0</th>
      <td>pop-film</td>
      <td>k-pop</td>
      <td>2.316352</td>
      <td>6.415646e-02</td>
      <td>-0.063477</td>
      <td>4.696182</td>
      <td>False</td>
    </tr>
    <tr>
      <th>34</th>
      <td>grunge</td>
      <td>sertanejo</td>
      <td>1.716583</td>
      <td>3.997287e-01</td>
      <td>-0.662057</td>
      <td>4.095222</td>
      <td>False</td>
    </tr>
    <tr>
      <th>33</th>
      <td>grunge</td>
      <td>pop</td>
      <td>1.679259</td>
      <td>4.359465e-01</td>
      <td>-0.703566</td>
      <td>4.062085</td>
      <td>False</td>
    </tr>
    <tr>
      <th>38</th>
      <td>indian</td>
      <td>sertanejo</td>
      <td>1.662529</td>
      <td>4.485840e-01</td>
      <td>-0.716111</td>
      <td>4.041168</td>
      <td>False</td>
    </tr>
    <tr>
      <th>37</th>
      <td>indian</td>
      <td>pop</td>
      <td>1.625205</td>
      <td>4.859952e-01</td>
      <td>-0.757620</td>
      <td>4.008031</td>
      <td>False</td>
    </tr>
    <tr>
      <th>32</th>
      <td>grunge</td>
      <td>emo</td>
      <td>1.454583</td>
      <td>6.448710e-01</td>
      <td>-0.924057</td>
      <td>3.833222</td>
      <td>False</td>
    </tr>
    <tr>
      <th>36</th>
      <td>indian</td>
      <td>emo</td>
      <td>1.400529</td>
      <td>6.941382e-01</td>
      <td>-0.978111</td>
      <td>3.779168</td>
      <td>False</td>
    </tr>
    <tr>
      <th>17</th>
      <td>chill</td>
      <td>sad</td>
      <td>1.325705</td>
      <td>7.582107e-01</td>
      <td>-1.052934</td>
      <td>3.704344</td>
      <td>False</td>
    </tr>
    <tr>
      <th>41</th>
      <td>anime</td>
      <td>sertanejo</td>
      <td>0.900767</td>
      <td>9.727925e-01</td>
      <td>-1.477872</td>
      <td>3.279406</td>
      <td>False</td>
    </tr>
    <tr>
      <th>40</th>
      <td>anime</td>
      <td>pop</td>
      <td>0.863444</td>
      <td>9.797852e-01</td>
      <td>-1.519382</td>
      <td>3.246269</td>
      <td>False</td>
    </tr>
    <tr>
      <th>31</th>
      <td>grunge</td>
      <td>anime</td>
      <td>0.815816</td>
      <td>9.862179e-01</td>
      <td>-1.563418</td>
      <td>3.195050</td>
      <td>False</td>
    </tr>
    <tr>
      <th>35</th>
      <td>indian</td>
      <td>anime</td>
      <td>0.761762</td>
      <td>9.915623e-01</td>
      <td>-1.617472</td>
      <td>3.140996</td>
      <td>False</td>
    </tr>
    <tr>
      <th>39</th>
      <td>anime</td>
      <td>emo</td>
      <td>0.638767</td>
      <td>9.977545e-01</td>
      <td>-1.739872</td>
      <td>3.017406</td>
      <td>False</td>
    </tr>
    <tr>
      <th>43</th>
      <td>emo</td>
      <td>sertanejo</td>
      <td>0.262000</td>
      <td>9.999987e-01</td>
      <td>-2.116044</td>
      <td>2.640044</td>
      <td>False</td>
    </tr>
    <tr>
      <th>42</th>
      <td>emo</td>
      <td>pop</td>
      <td>0.224677</td>
      <td>9.999997e-01</td>
      <td>-2.157555</td>
      <td>2.606908</td>
      <td>False</td>
    </tr>
    <tr>
      <th>30</th>
      <td>grunge</td>
      <td>indian</td>
      <td>0.054054</td>
      <td>1.000000e+00</td>
      <td>-2.325180</td>
      <td>2.433288</td>
      <td>False</td>
    </tr>
    <tr>
      <th>44</th>
      <td>pop</td>
      <td>sertanejo</td>
      <td>0.037323</td>
      <td>1.000000e+00</td>
      <td>-2.344908</td>
      <td>2.419555</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div id="66b7a324" class="cell markdown">
<p>From this result of the HSD test and it's table, you can see that the
categories <strong>pop-film, film, and chill</strong> were the majority
of the <em>significant difference</em> when comparisons where made
between genres. This suggests that pop-film, k-pop, and chill are are
significantly more popular than emo, anime, indian, grunge, sertanejo,
sad, and pop as the <strong>conclusion</strong>.</p>
</div>
<div id="21b6c8c4" class="cell markdown">
<p>Below I've plotted the Top 10 Most Popular Genres to show that this
relationship found can also be seen from a simple averaging of
popularity scores on the track_genres.</p>
</div>
<div id="d05be3b2" class="cell code" data-execution_count="44">
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute mean popularity</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>mean_popularity <span class="op">=</span> df_top10.groupby(<span class="st">&#39;track_genre&#39;</span>)[<span class="st">&#39;popularity&#39;</span>].mean().sort_values(ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">6</span>))</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>sns.barplot(x<span class="op">=</span>mean_popularity.index, y<span class="op">=</span>mean_popularity.values, palette<span class="op">=</span><span class="st">&quot;viridis&quot;</span>)</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Top 10 Most Popular Genres by Average Popularity&#39;</span>)</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Mean Popularity&#39;</span>)</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Genre&#39;</span>)</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output stream stderr">
<pre><code>/var/folders/tv/89ds0n_563nfsn6bpr8c6fv00000gn/T/ipykernel_43264/3331727488.py:5: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=mean_popularity.index, y=mean_popularity.values, palette=&quot;viridis&quot;)
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/0c0e2a53c40d4b0148b19fc1d70a9a8a8d0c88f4.png" /></p>
</div>
</div>
<div id="11f88308" class="cell markdown">
<h3
id="-q3-are-songs-in-a-major-key-more-popular-than-songs-in-a-minor-key-how-about-explicit-vs-non-explicit">🎯
Q3: Are songs in a major key more popular than songs in a minor key? How
about explicit vs non-explicit?</h3>
</div>
<div id="683b9b16" class="cell markdown">
<p>Let's separate the songs between those that are in major vs minor
key.</p>
</div>
<div id="7f02460f" class="cell code" data-execution_count="45">
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>songs_in_minor_keys <span class="op">=</span> spotify_df[spotify_df[<span class="st">&quot;mode&quot;</span>] <span class="op">==</span> <span class="dv">0</span>]</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>songs_in_major_keys <span class="op">=</span> spotify_df[spotify_df[<span class="st">&quot;mode&quot;</span>] <span class="op">==</span> <span class="dv">1</span>]</span></code></pre></div>
</div>
<div id="8676f608" class="cell code" data-execution_count="46">
<div class="sourceCode" id="cb39"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>songs_in_minor_keys.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="46">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>track_id</th>
      <th>artists</th>
      <th>album_name</th>
      <th>track_name</th>
      <th>popularity</th>
      <th>duration_ms</th>
      <th>explicit</th>
      <th>danceability</th>
      <th>energy</th>
      <th>key</th>
      <th>...</th>
      <th>speechiness</th>
      <th>acousticness</th>
      <th>instrumentalness</th>
      <th>liveness</th>
      <th>valence</th>
      <th>tempo</th>
      <th>time_signature</th>
      <th>track_genre</th>
      <th>track_genre_freq</th>
      <th>track_genre_target_enc</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5SuOikwiRyPMVoIQDJUgSV</td>
      <td>Gen Hoshino</td>
      <td>Comedy</td>
      <td>Comedy</td>
      <td>73</td>
      <td>230666</td>
      <td>False</td>
      <td>0.676</td>
      <td>0.4610</td>
      <td>1</td>
      <td>...</td>
      <td>0.1430</td>
      <td>0.0322</td>
      <td>0.000001</td>
      <td>0.3580</td>
      <td>0.715</td>
      <td>87.917</td>
      <td>4</td>
      <td>acoustic</td>
      <td>1000</td>
      <td>42.483</td>
    </tr>
    <tr>
      <th>12</th>
      <td>4ptDJbJl35d7gQfeNteBwp</td>
      <td>Dan Berk</td>
      <td>Solo</td>
      <td>Solo</td>
      <td>52</td>
      <td>198712</td>
      <td>False</td>
      <td>0.489</td>
      <td>0.3140</td>
      <td>7</td>
      <td>...</td>
      <td>0.0331</td>
      <td>0.7490</td>
      <td>0.000000</td>
      <td>0.1130</td>
      <td>0.607</td>
      <td>124.234</td>
      <td>4</td>
      <td>acoustic</td>
      <td>1000</td>
      <td>42.483</td>
    </tr>
    <tr>
      <th>17</th>
      <td>4Yo0igmcoNyat1secaH0OD</td>
      <td>Andrew Foy;Renee Foy</td>
      <td>At My Worst</td>
      <td>At My Worst</td>
      <td>54</td>
      <td>169728</td>
      <td>False</td>
      <td>0.795</td>
      <td>0.0841</td>
      <td>10</td>
      <td>...</td>
      <td>0.0461</td>
      <td>0.7420</td>
      <td>0.000012</td>
      <td>0.0853</td>
      <td>0.609</td>
      <td>91.803</td>
      <td>4</td>
      <td>acoustic</td>
      <td>1000</td>
      <td>42.483</td>
    </tr>
    <tr>
      <th>24</th>
      <td>3Hn3LfhrQOaKihdCibJsTs</td>
      <td>Jason Mraz</td>
      <td>Human - Best Adult Pop Tunes</td>
      <td>Unlonely</td>
      <td>0</td>
      <td>231266</td>
      <td>False</td>
      <td>0.796</td>
      <td>0.6670</td>
      <td>5</td>
      <td>...</td>
      <td>0.0392</td>
      <td>0.3810</td>
      <td>0.000000</td>
      <td>0.2210</td>
      <td>0.754</td>
      <td>97.988</td>
      <td>4</td>
      <td>acoustic</td>
      <td>1000</td>
      <td>42.483</td>
    </tr>
    <tr>
      <th>25</th>
      <td>6D33wCKzWtNEgOovgeVJ7r</td>
      <td>Jason Mraz</td>
      <td>Mellow Adult Pop</td>
      <td>Bella Luna</td>
      <td>1</td>
      <td>302346</td>
      <td>False</td>
      <td>0.755</td>
      <td>0.4540</td>
      <td>9</td>
      <td>...</td>
      <td>0.0352</td>
      <td>0.7570</td>
      <td>0.000000</td>
      <td>0.2360</td>
      <td>0.330</td>
      <td>120.060</td>
      <td>4</td>
      <td>acoustic</td>
      <td>1000</td>
      <td>42.483</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 22 columns</p>
</div>
</div>
</div>
<div id="d0391fa7" class="cell code" data-execution_count="47">
<div class="sourceCode" id="cb40"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>songs_in_major_keys.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="47">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>track_id</th>
      <th>artists</th>
      <th>album_name</th>
      <th>track_name</th>
      <th>popularity</th>
      <th>duration_ms</th>
      <th>explicit</th>
      <th>danceability</th>
      <th>energy</th>
      <th>key</th>
      <th>...</th>
      <th>speechiness</th>
      <th>acousticness</th>
      <th>instrumentalness</th>
      <th>liveness</th>
      <th>valence</th>
      <th>tempo</th>
      <th>time_signature</th>
      <th>track_genre</th>
      <th>track_genre_freq</th>
      <th>track_genre_target_enc</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>4qPNDBW1i3p13qLCt0Ki3A</td>
      <td>Ben Woodward</td>
      <td>Ghost (Acoustic)</td>
      <td>Ghost - Acoustic</td>
      <td>55</td>
      <td>149610</td>
      <td>False</td>
      <td>0.420</td>
      <td>0.1660</td>
      <td>1</td>
      <td>...</td>
      <td>0.0763</td>
      <td>0.924</td>
      <td>0.000006</td>
      <td>0.1010</td>
      <td>0.267</td>
      <td>77.489</td>
      <td>4</td>
      <td>acoustic</td>
      <td>1000</td>
      <td>42.483</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1iJBSr7s7jYXzM8EGcbK5b</td>
      <td>Ingrid Michaelson;ZAYN</td>
      <td>To Begin Again</td>
      <td>To Begin Again</td>
      <td>57</td>
      <td>210826</td>
      <td>False</td>
      <td>0.438</td>
      <td>0.3590</td>
      <td>0</td>
      <td>...</td>
      <td>0.0557</td>
      <td>0.210</td>
      <td>0.000000</td>
      <td>0.1170</td>
      <td>0.120</td>
      <td>76.332</td>
      <td>4</td>
      <td>acoustic</td>
      <td>1000</td>
      <td>42.483</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6lfxq3CG4xtTiEg7opyCyx</td>
      <td>Kina Grannis</td>
      <td>Crazy Rich Asians (Original Motion Picture Sou...</td>
      <td>Can't Help Falling In Love</td>
      <td>71</td>
      <td>201933</td>
      <td>False</td>
      <td>0.266</td>
      <td>0.0596</td>
      <td>0</td>
      <td>...</td>
      <td>0.0363</td>
      <td>0.905</td>
      <td>0.000071</td>
      <td>0.1320</td>
      <td>0.143</td>
      <td>181.740</td>
      <td>3</td>
      <td>acoustic</td>
      <td>1000</td>
      <td>42.483</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5vjLSffimiIP26QG5WcN2K</td>
      <td>Chord Overstreet</td>
      <td>Hold On</td>
      <td>Hold On</td>
      <td>82</td>
      <td>198853</td>
      <td>False</td>
      <td>0.618</td>
      <td>0.4430</td>
      <td>2</td>
      <td>...</td>
      <td>0.0526</td>
      <td>0.469</td>
      <td>0.000000</td>
      <td>0.0829</td>
      <td>0.167</td>
      <td>119.949</td>
      <td>4</td>
      <td>acoustic</td>
      <td>1000</td>
      <td>42.483</td>
    </tr>
    <tr>
      <th>5</th>
      <td>01MVOl9KtVTNfFiBU9I7dc</td>
      <td>Tyrone Wells</td>
      <td>Days I Will Remember</td>
      <td>Days I Will Remember</td>
      <td>58</td>
      <td>214240</td>
      <td>False</td>
      <td>0.688</td>
      <td>0.4810</td>
      <td>6</td>
      <td>...</td>
      <td>0.1050</td>
      <td>0.289</td>
      <td>0.000000</td>
      <td>0.1890</td>
      <td>0.666</td>
      <td>98.017</td>
      <td>4</td>
      <td>acoustic</td>
      <td>1000</td>
      <td>42.483</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 22 columns</p>
</div>
</div>
</div>
<div id="46687096" class="cell markdown">
<p>Let's look at the distribution of the popularity of the songs in
minor keys.</p>
</div>
<div id="2eea922b" class="cell code" data-execution_count="48">
<div class="sourceCode" id="cb41"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>songs_in_minor_keys[<span class="st">&quot;popularity&quot;</span>].plot(kind <span class="op">=</span> <span class="st">&#39;hist&#39;</span>)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/7cbd03617282ffdbb9b0bd3c7626fc30b38cdd6d.png" /></p>
</div>
</div>
<div id="bc59656d" class="cell markdown">
<p>Let's look at the distribution of the popularity of the songs in
major keys.</p>
</div>
<div id="4f5a4e49" class="cell code" data-execution_count="49">
<div class="sourceCode" id="cb42"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>songs_in_major_keys[<span class="st">&quot;popularity&quot;</span>].plot(kind <span class="op">=</span> <span class="st">&#39;hist&#39;</span>)</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/d6757afcec70105c83eec77de36ac559534f8bb0.png" /></p>
</div>
</div>
<div id="83fcb84f" class="cell markdown">
<p>These qqplots (Quantile-Quantile Plots) confirm that the distribution
of the popularity for both major and minor key songs are not normal. If
the distributions were normal, then the scatter would fit close to the
line shown below, however, we can see some deviation on the ends of the
theoretical quantiles, which suggests a more "dispersed" distribution.
This aligns with what we see in the histograms.</p>
</div>
<div id="87acf821" class="cell code" data-execution_count="50">
<div class="sourceCode" id="cb43"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Credit: https://www.geeksforgeeks.org/machine-learning/quantile-quantile-plots/</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>stats.probplot(songs_in_minor_keys[<span class="st">&#39;popularity&#39;</span>], dist<span class="op">=</span><span class="st">&quot;norm&quot;</span>, plot<span class="op">=</span>plt)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Normal Q-Q plot&#39;</span>)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Theoretical quantiles&#39;</span>)</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Ordered Values&#39;</span>)</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a><span class="co">#fig = sm.qqplot(songs_in_minor_keys[&#39;popularity&#39;], line=&#39;45&#39;)</span></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/061b37695384825d212bddb974a545df59522cad.png" /></p>
</div>
</div>
<div id="c2d7d5eb" class="cell code" data-execution_count="51">
<div class="sourceCode" id="cb44"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Credit: https://www.geeksforgeeks.org/machine-learning/quantile-quantile-plots/</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>stats.probplot(songs_in_major_keys[<span class="st">&#39;popularity&#39;</span>], dist<span class="op">=</span><span class="st">&quot;norm&quot;</span>, plot<span class="op">=</span>plt)</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Normal Q-Q plot&#39;</span>)</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Theoretical quantiles&#39;</span>)</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Ordered Values&#39;</span>)</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a><span class="co">#fig = sm.qqplot(songs_in_major_keys[&#39;popularity&#39;], line=&#39;45&#39;)</span></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/214854c81109b424dc52415cf656464a1ddad7a3.png" /></p>
</div>
</div>
<div id="5bf64600" class="cell markdown">
<p>Note that from the above results it is clear that these two
populations are not normal. Hence we must use the Man Whiteny U test
instead. <br> H_0: The popularity in major key and minor key come from
the same distribution. <br> H_a: The popularity in major key and minor
key come from the different distributions.</p>
</div>
<div id="8e175aae" class="cell code" data-execution_count="52">
<div class="sourceCode" id="cb45"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>major_key_popularities <span class="op">=</span> songs_in_major_keys[<span class="st">&quot;popularity&quot;</span>]</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>minor_key_popularities <span class="op">=</span> songs_in_minor_keys[<span class="st">&quot;popularity&quot;</span>]</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>stat, p_val <span class="op">=</span> stats.mannwhitneyu(major_key_popularities, minor_key_popularities)</span></code></pre></div>
</div>
<div id="ec53ff7b" class="cell code" data-execution_count="53">
<div class="sourceCode" id="cb46"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;The p-value is&quot;</span>, p_val, <span class="st">&quot;.&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>The p-value is 1.593987121786141e-07 .
</code></pre>
</div>
</div>
<div id="96e5d361" class="cell code" data-execution_count="54">
<div class="sourceCode" id="cb48"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> p_val <span class="op">&lt;</span> <span class="fl">0.01</span>:</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;Reject the null hypothesis: There is a statistically significant difference in the distribution of popularity between the major key and minor keys.&quot;</span>)</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;Fail to reject the null hypothesis: No statistically significant difference in the distribution of popularity between the two groups.&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Reject the null hypothesis: There is a statistically significant difference in the distribution of popularity between the major key and minor keys.
</code></pre>
</div>
</div>
<div id="f419f39e" class="cell markdown">
<p>The above Man Whiteney U test suggests that there is sufficient
evidence to reject the null hypothesis that the distributions of
popularity between major and minor keys is the same. Instead, we
conclude that the distributions must be different: thus the key likely
has an influence on popularity.</p>
</div>
<div id="bce7181c" class="cell code" data-execution_count="55">
<div class="sourceCode" id="cb50"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="bu">float</span>(major_key_popularities.mean())</span></code></pre></div>
<div class="output execute_result" data-execution_count="55">
<pre><code>33.0724295516989</code></pre>
</div>
</div>
<div id="6c2a50a5" class="cell code" data-execution_count="56">
<div class="sourceCode" id="cb52"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="bu">float</span>(minor_key_popularities.mean())</span></code></pre></div>
<div class="output execute_result" data-execution_count="56">
<pre><code>33.76831225680934</code></pre>
</div>
</div>
<div id="1cae834f" class="cell markdown">
<p>We see that the means from both distributions are quite similar,
despite being from different distributions.</p>
</div>
<div id="1fcce12a" class="cell code" data-execution_count="57">
<div class="sourceCode" id="cb54"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the popularity means for explicit and nonexplicit songs</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>mean_major <span class="op">=</span> major_key_popularities.mean()</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>mean_minor <span class="op">=</span> minor_key_popularities.mean()</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Group songs by explicit/non-explicit status and show popularity</span></span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>grouped <span class="op">=</span> spotify_df.groupby(<span class="st">&#39;mode&#39;</span>)[<span class="st">&#39;popularity&#39;</span>]</span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a><span class="co">###############################################################################</span></span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a><span class="co"># BOXPLOT GRAPH</span></span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Credit to: https://python-graph-gallery.com/551-student-t-test-visualization/</span></span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-12"><a href="#cb54-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Init a figure and axes</span></span>
<span id="cb54-13"><a href="#cb54-13" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb54-14"><a href="#cb54-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-15"><a href="#cb54-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the plot with different colors for each group</span></span>
<span id="cb54-16"><a href="#cb54-16" aria-hidden="true" tabindex="-1"></a>boxplot <span class="op">=</span> ax.boxplot(x<span class="op">=</span>[group.values <span class="cf">for</span> name, group <span class="kw">in</span> grouped],</span>
<span id="cb54-17"><a href="#cb54-17" aria-hidden="true" tabindex="-1"></a>                     labels<span class="op">=</span>[<span class="st">&quot;Major&quot;</span>, <span class="st">&quot;Minor&quot;</span>],</span>
<span id="cb54-18"><a href="#cb54-18" aria-hidden="true" tabindex="-1"></a>                     patch_artist<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb54-19"><a href="#cb54-19" aria-hidden="true" tabindex="-1"></a>                     medianprops<span class="op">=</span>{<span class="st">&#39;color&#39;</span>: <span class="st">&#39;black&#39;</span>}</span>
<span id="cb54-20"><a href="#cb54-20" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb54-21"><a href="#cb54-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-22"><a href="#cb54-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Define colors for each group</span></span>
<span id="cb54-23"><a href="#cb54-23" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">&#39;red&#39;</span>, <span class="st">&#39;blue&#39;</span>]</span>
<span id="cb54-24"><a href="#cb54-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-25"><a href="#cb54-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Assign colors to each box in the boxplot</span></span>
<span id="cb54-26"><a href="#cb54-26" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> box, color <span class="kw">in</span> <span class="bu">zip</span>(boxplot[<span class="st">&#39;boxes&#39;</span>], colors):</span>
<span id="cb54-27"><a href="#cb54-27" aria-hidden="true" tabindex="-1"></a>    box.set_facecolor(color)</span>
<span id="cb54-28"><a href="#cb54-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-29"><a href="#cb54-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the mean for each group</span></span>
<span id="cb54-30"><a href="#cb54-30" aria-hidden="true" tabindex="-1"></a>ax.text(<span class="fl">1.1</span>, mean_major, <span class="ss">f&#39;Major: </span><span class="sc">{</span>mean_major<span class="sc">:.2f}</span><span class="ss">&#39;</span>)</span>
<span id="cb54-31"><a href="#cb54-31" aria-hidden="true" tabindex="-1"></a>ax.text(<span class="fl">1.64</span>, mean_minor, <span class="ss">f&#39;Minor: </span><span class="sc">{</span>mean_minor<span class="sc">:.2f}</span><span class="ss">&#39;</span>)</span>
<span id="cb54-32"><a href="#cb54-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-33"><a href="#cb54-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a title and axis label</span></span>
<span id="cb54-34"><a href="#cb54-34" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">&#39;Popularity Distribution between Major and Minor Songs&#39;</span>)</span>
<span id="cb54-35"><a href="#cb54-35" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">&#39;Popularity&#39;</span>)</span>
<span id="cb54-36"><a href="#cb54-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-37"><a href="#cb54-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Display it</span></span>
<span id="cb54-38"><a href="#cb54-38" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output stream stderr">
<pre><code>/var/folders/tv/89ds0n_563nfsn6bpr8c6fv00000gn/T/ipykernel_43264/3213480038.py:16: MatplotlibDeprecationWarning: The &#39;labels&#39; parameter of boxplot() has been renamed &#39;tick_labels&#39; since Matplotlib 3.9; support for the old name will be dropped in 3.11.
  boxplot = ax.boxplot(x=[group.values for name, group in grouped],
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/561d07e94144fd2a0b21c899ed343bb8690be9f3.png" /></p>
</div>
</div>
<div id="d15ce838" class="cell markdown">
<h3
id="now-lets-look-at-the-difference-in-popularity-between-explicit-and-non-explicit-songs">Now
let's look at the difference in popularity between explicit and
non-explicit songs.</h3>
</div>
<div id="ea477bad" class="cell code" data-execution_count="58">
<div class="sourceCode" id="cb56"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>explicit_songs <span class="op">=</span> spotify_df[spotify_df[<span class="st">&quot;explicit&quot;</span>] <span class="op">==</span> <span class="va">True</span>]</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>non_explicit_songs <span class="op">=</span> spotify_df[spotify_df[<span class="st">&quot;explicit&quot;</span>] <span class="op">==</span> <span class="va">False</span>]</span></code></pre></div>
</div>
<div id="4582a050" class="cell code" data-execution_count="59">
<div class="sourceCode" id="cb57"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>explicit_songs[<span class="st">&quot;popularity&quot;</span>].plot(kind <span class="op">=</span> <span class="st">&#39;hist&#39;</span>)</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/dd55d531772f0e22215c75b2747f25029bc843ad.png" /></p>
</div>
</div>
<div id="7e9f291e" class="cell code" data-execution_count="60">
<div class="sourceCode" id="cb58"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>non_explicit_songs[<span class="st">&quot;popularity&quot;</span>].plot(kind <span class="op">=</span> <span class="st">&#39;hist&#39;</span>)</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/32ea170d18db34ca93a1cdb785fd02da5620ae7f.png" /></p>
</div>
</div>
<div id="53684319" class="cell markdown">
<p>Similar to the major/minor popularity distributions, these do not
have a normal bell-shape either. Let's look at the Q-Q Plots.</p>
</div>
<div id="ba7ee970" class="cell code" data-execution_count="61">
<div class="sourceCode" id="cb59"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Credit: https://www.geeksforgeeks.org/machine-learning/quantile-quantile-plots/</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>stats.probplot(explicit_songs[<span class="st">&#39;popularity&#39;</span>], dist<span class="op">=</span><span class="st">&quot;norm&quot;</span>, plot<span class="op">=</span>plt)</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Normal Q-Q plot&#39;</span>)</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Theoretical quantiles&#39;</span>)</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Ordered Values&#39;</span>)</span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a><span class="co">#explicit_songs_popularity_distr = sm.qqplot(explicit_songs[&#39;popularity&#39;], line=&#39;45&#39;)</span></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/4130fe4cadb08f71b88e37433af40f8779dbf9ef.png" /></p>
</div>
</div>
<div id="a552a514" class="cell code" data-execution_count="62">
<div class="sourceCode" id="cb60"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Credit: https://www.geeksforgeeks.org/machine-learning/quantile-quantile-plots/</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>stats.probplot(non_explicit_songs[<span class="st">&#39;popularity&#39;</span>], dist<span class="op">=</span><span class="st">&quot;norm&quot;</span>, plot<span class="op">=</span>plt)</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Normal Q-Q plot&#39;</span>)</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Theoretical quantiles&#39;</span>)</span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Ordered Values&#39;</span>)</span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a><span class="co">#nonexplicit_songs_popularity_dist = sm.qqplot(non_explicit_songs[&#39;popularity&#39;], line=&#39;45&#39;)</span></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/bc067e57b8f4b442f42359ef913134a4558de8b1.png" /></p>
</div>
</div>
<div id="26c51f92" class="cell markdown">
<p>Note that from the above results it is clear that these two
populations are not normal. Hence we must use the Man Whiteny U test
instead. <br> H_0: The popularity of explicit and non-explicit songs
come from the same distribution. <br> H_a: The popularity of explicit
and non-explicit songs come from different distributions.</p>
</div>
<div id="1a82d5fc" class="cell code" data-execution_count="63">
<div class="sourceCode" id="cb61"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>explicit_song_popularities <span class="op">=</span> explicit_songs[<span class="st">&quot;popularity&quot;</span>]</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>non_explicit_song_popularities <span class="op">=</span> non_explicit_songs[<span class="st">&quot;popularity&quot;</span>]</span></code></pre></div>
</div>
<div id="f569d526" class="cell code" data-execution_count="64">
<div class="sourceCode" id="cb62"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>stat_e, p_val_e <span class="op">=</span> stats.mannwhitneyu(explicit_song_popularities, non_explicit_song_popularities)</span></code></pre></div>
</div>
<div id="320f91b9" class="cell code" data-execution_count="65">
<div class="sourceCode" id="cb63"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;The p-value is&quot;</span>, p_val_e, <span class="st">&quot;.&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>The p-value is 1.3317030463864243e-41 .
</code></pre>
</div>
</div>
<div id="030a1564" class="cell code" data-execution_count="66">
<div class="sourceCode" id="cb65"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> p_val_e <span class="op">&lt;</span> <span class="fl">0.01</span>:</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;Reject the null hypothesis: There is a statistically significant difference in the distribution of popularity between explicit songs and non-explicit songs.&quot;</span>)</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;Fail to reject the null hypothesis: No statistically significant difference in the distribution of popularity between between explicit songs and non-explicit songs.&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Reject the null hypothesis: There is a statistically significant difference in the distribution of popularity between explicit songs and non-explicit songs.
</code></pre>
</div>
</div>
<div id="02ef3d74" class="cell code" data-execution_count="67">
<div class="sourceCode" id="cb67"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the popularity means for explicit and nonexplicit songs</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>mean_explicit <span class="op">=</span> explicit_song_popularities.mean()</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>mean_non_explicit <span class="op">=</span> non_explicit_song_popularities.mean()</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Group songs by explicit/non-explicit status and show popularity</span></span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a>grouped <span class="op">=</span> spotify_df.groupby(<span class="st">&#39;explicit&#39;</span>)[<span class="st">&#39;popularity&#39;</span>]</span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a><span class="co">###############################################################################</span></span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a><span class="co"># BOXPLOT GRAPH</span></span>
<span id="cb67-10"><a href="#cb67-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Credit to: https://python-graph-gallery.com/551-student-t-test-visualization/</span></span>
<span id="cb67-11"><a href="#cb67-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-12"><a href="#cb67-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Init a figure and axes</span></span>
<span id="cb67-13"><a href="#cb67-13" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb67-14"><a href="#cb67-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-15"><a href="#cb67-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the plot with different colors for each group</span></span>
<span id="cb67-16"><a href="#cb67-16" aria-hidden="true" tabindex="-1"></a>boxplot <span class="op">=</span> ax.boxplot(x<span class="op">=</span>[group.values <span class="cf">for</span> name, group <span class="kw">in</span> grouped],</span>
<span id="cb67-17"><a href="#cb67-17" aria-hidden="true" tabindex="-1"></a>                     labels<span class="op">=</span>[<span class="st">&quot;Explicit&quot;</span>, <span class="st">&quot;Non-Explicit&quot;</span>],</span>
<span id="cb67-18"><a href="#cb67-18" aria-hidden="true" tabindex="-1"></a>                     patch_artist<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb67-19"><a href="#cb67-19" aria-hidden="true" tabindex="-1"></a>                     medianprops<span class="op">=</span>{<span class="st">&#39;color&#39;</span>: <span class="st">&#39;black&#39;</span>}</span>
<span id="cb67-20"><a href="#cb67-20" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb67-21"><a href="#cb67-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-22"><a href="#cb67-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Define colors for each group</span></span>
<span id="cb67-23"><a href="#cb67-23" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">&#39;red&#39;</span>, <span class="st">&#39;blue&#39;</span>]</span>
<span id="cb67-24"><a href="#cb67-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-25"><a href="#cb67-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Assign colors to each box in the boxplot</span></span>
<span id="cb67-26"><a href="#cb67-26" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> box, color <span class="kw">in</span> <span class="bu">zip</span>(boxplot[<span class="st">&#39;boxes&#39;</span>], colors):</span>
<span id="cb67-27"><a href="#cb67-27" aria-hidden="true" tabindex="-1"></a>    box.set_facecolor(color)</span>
<span id="cb67-28"><a href="#cb67-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-29"><a href="#cb67-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the mean for each group</span></span>
<span id="cb67-30"><a href="#cb67-30" aria-hidden="true" tabindex="-1"></a>ax.text(<span class="fl">1.1</span>, mean_explicit, <span class="ss">f&#39;Mean: </span><span class="sc">{</span>mean_explicit<span class="sc">:.2f}</span><span class="ss">&#39;</span>)</span>
<span id="cb67-31"><a href="#cb67-31" aria-hidden="true" tabindex="-1"></a>ax.text(<span class="fl">1.64</span>, mean_non_explicit, <span class="ss">f&#39;Mean: </span><span class="sc">{</span>mean_non_explicit<span class="sc">:.2f}</span><span class="ss">&#39;</span>)</span>
<span id="cb67-32"><a href="#cb67-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-33"><a href="#cb67-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a title and axis label</span></span>
<span id="cb67-34"><a href="#cb67-34" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">&#39;Popularity Distribution between Explicit and Non-Explicit Songs&#39;</span>)</span>
<span id="cb67-35"><a href="#cb67-35" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">&#39;Popularity&#39;</span>)</span>
<span id="cb67-36"><a href="#cb67-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-37"><a href="#cb67-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Display it</span></span>
<span id="cb67-38"><a href="#cb67-38" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output stream stderr">
<pre><code>/var/folders/tv/89ds0n_563nfsn6bpr8c6fv00000gn/T/ipykernel_43264/4160170839.py:16: MatplotlibDeprecationWarning: The &#39;labels&#39; parameter of boxplot() has been renamed &#39;tick_labels&#39; since Matplotlib 3.9; support for the old name will be dropped in 3.11.
  boxplot = ax.boxplot(x=[group.values for name, group in grouped],
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/fa74494258366768be7d50654fde59dd31740772.png" /></p>
</div>
</div>
<div id="d72fb56f" class="cell markdown">
<h2 id="iv-machine-learning-analysis">IV. Machine Learning Analysis</h2>
</div>
<div id="a72d14f7" class="cell markdown">
<p>After testing multiple model LinearRegression, SVR,
RandomForestRegressor, KNN, Neural Network, XGBoost to predict the
popularity of a song. The best results came from the KNN model which
received a score of 12.16 on the RMSE test and a 0.70 R squared value.
Therefore, the ML analysis will only guide you through our work from the
K-NN, but the work the team did on the other models is attached at the
bottom of the notebook for reference. Another approach we decided to do
after a underwhelming results from the regression model was to take a
classification approach. The songs were categorized into 3 categories
(low, medium, and high popularity) then a RandomForstClassifier was
used.</p>
</div>
<div id="8c5cd002" class="cell markdown">
<h3 id="k-nearest-neighbors">K-Nearest Neighbors</h3>
</div>
<div id="d6ef25d1" class="cell code">
<div class="sourceCode" id="cb69"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsRegressor</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_score</span></code></pre></div>
</div>
<div id="15e49c05" class="cell code">
<div class="sourceCode" id="cb70"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>artists_popularity_map <span class="op">=</span> spotify_df.groupby(<span class="st">&#39;artists&#39;</span>)[<span class="st">&#39;popularity&#39;</span>].mean()</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>spotify_df[<span class="st">&#39;artists_target_enc&#39;</span>] <span class="op">=</span> spotify_df[<span class="st">&#39;artists&#39;</span>].<span class="bu">map</span>(artists_popularity_map)</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a><span class="co">#encode explicit as 1 or 0</span></span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>spotify_df[<span class="st">&#39;explicit_enc&#39;</span>] <span class="op">=</span> spotify_df[<span class="st">&#39;explicit&#39;</span>].<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x <span class="cf">else</span> <span class="dv">0</span>)</span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a><span class="co">#drop non-numeric columns</span></span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> spotify_df.drop(columns<span class="op">=</span>[<span class="st">&#39;popularity&#39;</span>, <span class="st">&#39;artists&#39;</span>, <span class="st">&#39;track_id&#39;</span>, <span class="st">&#39;album_name&#39;</span>, <span class="st">&#39;track_name&#39;</span>, <span class="st">&#39;explicit&#39;</span>, <span class="st">&#39;track_genre&#39;</span>, <span class="st">&#39;track_genre_freq&#39;</span>])</span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> spotify_df[<span class="st">&#39;popularity&#39;</span>]</span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a>display(X.head())</span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a>display(y.head())</span>
<span id="cb70-12"><a href="#cb70-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-13"><a href="#cb70-13" aria-hidden="true" tabindex="-1"></a>display(X.dtypes)</span>
<span id="cb70-14"><a href="#cb70-14" aria-hidden="true" tabindex="-1"></a>display(y.dtypes)</span>
<span id="cb70-15"><a href="#cb70-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-16"><a href="#cb70-16" aria-hidden="true" tabindex="-1"></a><span class="co">#Convert type of data into floats</span></span>
<span id="cb70-17"><a href="#cb70-17" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> X.astype(<span class="st">&#39;float32&#39;</span>)</span>
<span id="cb70-18"><a href="#cb70-18" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> y.astype(<span class="st">&#39;float32&#39;</span>)</span>
<span id="cb70-19"><a href="#cb70-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-20"><a href="#cb70-20" aria-hidden="true" tabindex="-1"></a>display(X.dtypes)</span>
<span id="cb70-21"><a href="#cb70-21" aria-hidden="true" tabindex="-1"></a>display(y.dtypes)</span>
<span id="cb70-22"><a href="#cb70-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-23"><a href="#cb70-23" aria-hidden="true" tabindex="-1"></a>random_state<span class="op">=</span> <span class="dv">42</span></span>
<span id="cb70-24"><a href="#cb70-24" aria-hidden="true" tabindex="-1"></a><span class="co">#Credit: HW4</span></span>
<span id="cb70-25"><a href="#cb70-25" aria-hidden="true" tabindex="-1"></a><span class="co">#split into train and test data</span></span>
<span id="cb70-26"><a href="#cb70-26" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span>random_state)</span>
<span id="cb70-27"><a href="#cb70-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-28"><a href="#cb70-28" aria-hidden="true" tabindex="-1"></a><span class="co">#Normalize</span></span>
<span id="cb70-29"><a href="#cb70-29" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb70-30"><a href="#cb70-30" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb70-31"><a href="#cb70-31" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> scaler.fit_transform(X_test)</span>
<span id="cb70-32"><a href="#cb70-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-33"><a href="#cb70-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to PyTorch tensors</span></span>
<span id="cb70-34"><a href="#cb70-34" aria-hidden="true" tabindex="-1"></a>X_train_tensor <span class="op">=</span> torch.tensor(X_train)</span>
<span id="cb70-35"><a href="#cb70-35" aria-hidden="true" tabindex="-1"></a>y_train_tensor <span class="op">=</span> torch.tensor(y_train.values)</span>
<span id="cb70-36"><a href="#cb70-36" aria-hidden="true" tabindex="-1"></a>X_test_tensor <span class="op">=</span> torch.tensor(X_test)</span>
<span id="cb70-37"><a href="#cb70-37" aria-hidden="true" tabindex="-1"></a>y_test_tensor <span class="op">=</span> torch.tensor(y_test.values)</span>
<span id="cb70-38"><a href="#cb70-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-39"><a href="#cb70-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Create data loaders</span></span>
<span id="cb70-40"><a href="#cb70-40" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> TensorDataset(X_train_tensor, y_train_tensor)</span>
<span id="cb70-41"><a href="#cb70-41" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> TensorDataset(X_test_tensor, y_test_tensor)</span>
<span id="cb70-42"><a href="#cb70-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-43"><a href="#cb70-43" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb70-44"><a href="#cb70-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-45"><a href="#cb70-45" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(train_dataset, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb70-46"><a href="#cb70-46" aria-hidden="true" tabindex="-1"></a>test_loader <span class="op">=</span> DataLoader(test_dataset, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb70-47"><a href="#cb70-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-48"><a href="#cb70-48" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> train_loader.batch_size</span>
<span id="cb70-49"><a href="#cb70-49" aria-hidden="true" tabindex="-1"></a>num_train_data <span class="op">=</span> <span class="bu">len</span>(train_loader) <span class="op">*</span> batch_size</span>
<span id="cb70-50"><a href="#cb70-50" aria-hidden="true" tabindex="-1"></a>num_test_data <span class="op">=</span> <span class="bu">len</span>(test_loader) <span class="op">*</span> batch_size</span>
<span id="cb70-51"><a href="#cb70-51" aria-hidden="true" tabindex="-1"></a>feat_dim <span class="op">=</span> train_loader.dataset[<span class="dv">0</span>][<span class="dv">0</span>].shape[<span class="dv">0</span>]</span></code></pre></div>
</div>
<div id="42d2ddfb" class="cell markdown">
<p>We must first determine the best value for k using cross
validation.</p>
</div>
<div id="398d55b1" class="cell code" data-execution_count="122">
<div class="sourceCode" id="cb71"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="co">#find the best cluster size</span></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> knn(cluster_size):</span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>    neigh <span class="op">=</span> KNeighborsRegressor(n_neighbors<span class="op">=</span>cluster_size, weights<span class="op">=</span> <span class="st">&#39;distance&#39;</span>)</span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a>    neigh.fit(X_train, y_train)</span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cross_val_score(neigh, X_train, y_train, cv<span class="op">=</span> <span class="dv">5</span>).mean() <span class="co">#5 folds</span></span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> []</span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a>cluster_sizes <span class="op">=</span> []</span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>, <span class="dv">70</span>, <span class="dv">5</span>):</span>
<span id="cb71-10"><a href="#cb71-10" aria-hidden="true" tabindex="-1"></a>    scores.append(knn(i))</span>
<span id="cb71-11"><a href="#cb71-11" aria-hidden="true" tabindex="-1"></a>    cluster_sizes.append(i)</span>
<span id="cb71-12"><a href="#cb71-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-13"><a href="#cb71-13" aria-hidden="true" tabindex="-1"></a>plt.plot(cluster_sizes, scores)</span></code></pre></div>
<div class="output execute_result" data-execution_count="122">
<pre><code>[&lt;matplotlib.lines.Line2D at 0x12918a5d0&gt;]</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/2aaec44f55cd1528a2211e355742cc45660b5ab6.png" /></p>
</div>
</div>
<div id="1541137b" class="cell markdown">
<p>It seems like the best cluster size is 25 with score ~0.7, after
which there is minimal benefit of increasing size.</p>
</div>
<div id="a00f40c8" class="cell code">
<div class="sourceCode" id="cb73"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co">## define code for visualizing the results</span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ml_visual(sample, target, preds):</span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a>    sample_df <span class="op">=</span> pd.DataFrame(sample, columns<span class="op">=</span> X.columns)</span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a>    target_df <span class="op">=</span> pd.DataFrame(target, columns<span class="op">=</span> [<span class="st">&#39;popularity&#39;</span>])</span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a>    preds_df <span class="op">=</span> pd.DataFrame(preds, columns<span class="op">=</span> [<span class="st">&#39;predicted_popularity&#39;</span>])</span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-7"><a href="#cb73-7" aria-hidden="true" tabindex="-1"></a>    sample_df <span class="op">=</span> sample_df.merge(target_df, left_index<span class="op">=</span><span class="va">True</span>, right_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb73-8"><a href="#cb73-8" aria-hidden="true" tabindex="-1"></a>    sample_df <span class="op">=</span> sample_df.merge(preds_df, left_index<span class="op">=</span><span class="va">True</span>, right_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb73-9"><a href="#cb73-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-10"><a href="#cb73-10" aria-hidden="true" tabindex="-1"></a>    display(sample_df.head(<span class="dv">10</span>))</span>
<span id="cb73-11"><a href="#cb73-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-12"><a href="#cb73-12" aria-hidden="true" tabindex="-1"></a>    plt.scatter(target, preds)</span>
<span id="cb73-13"><a href="#cb73-13" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">&#39;actual popularity&#39;</span>)</span>
<span id="cb73-14"><a href="#cb73-14" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">&#39;predicted popularity&#39;</span>)</span>
<span id="cb73-15"><a href="#cb73-15" aria-hidden="true" tabindex="-1"></a>    plt.plot(target, target)</span>
<span id="cb73-16"><a href="#cb73-16" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code></pre></div>
</div>
<div id="867e74ba" class="cell code" data-execution_count="123">
<div class="sourceCode" id="cb74"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>neigh <span class="op">=</span> KNeighborsRegressor(n_neighbors<span class="op">=</span><span class="dv">25</span>, weights<span class="op">=</span> <span class="st">&#39;distance&#39;</span>)</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>neigh.fit(X_train, y_train)</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> neigh.predict(X_test)</span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a>sample <span class="op">=</span> X_test</span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> y_test</span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-9"><a href="#cb74-9" aria-hidden="true" tabindex="-1"></a>ml_visual(sample, target, preds)</span></code></pre></div>
<div class="output display_data">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>duration_ms</th>
      <th>danceability</th>
      <th>energy</th>
      <th>key</th>
      <th>loudness</th>
      <th>mode</th>
      <th>speechiness</th>
      <th>acousticness</th>
      <th>instrumentalness</th>
      <th>liveness</th>
      <th>valence</th>
      <th>tempo</th>
      <th>time_signature</th>
      <th>track_genre_target_enc</th>
      <th>artists_target_enc</th>
      <th>explicit_enc</th>
      <th>popularity</th>
      <th>predicted_popularity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3</th>
      <td>0.532040</td>
      <td>-1.643113</td>
      <td>-1.988699</td>
      <td>-0.367280</td>
      <td>-2.160372</td>
      <td>-1.335451</td>
      <td>-0.482557</td>
      <td>1.993330</td>
      <td>2.354289</td>
      <td>-0.580892</td>
      <td>-1.038870</td>
      <td>0.441346</td>
      <td>-2.062984</td>
      <td>-0.374213</td>
      <td>-0.559937</td>
      <td>-0.30251</td>
      <td>71.0</td>
      <td>29.293007</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.437469</td>
      <td>-0.294569</td>
      <td>0.871115</td>
      <td>-1.492911</td>
      <td>0.025093</td>
      <td>0.748811</td>
      <td>-0.182322</td>
      <td>-0.947184</td>
      <td>-0.494433</td>
      <td>-0.136190</td>
      <td>-0.510412</td>
      <td>0.462796</td>
      <td>0.225414</td>
      <td>-0.096352</td>
      <td>-0.286441</td>
      <td>3.30568</td>
      <td>0.0</td>
      <td>30.457305</td>
    </tr>
    <tr>
      <th>24</th>
      <td>-0.098566</td>
      <td>1.503490</td>
      <td>-0.326109</td>
      <td>1.039759</td>
      <td>0.395359</td>
      <td>-1.335451</td>
      <td>-0.215040</td>
      <td>-0.813734</td>
      <td>-0.503743</td>
      <td>-0.844537</td>
      <td>1.063391</td>
      <td>0.730004</td>
      <td>0.225414</td>
      <td>0.659819</td>
      <td>0.024792</td>
      <td>-0.30251</td>
      <td>0.0</td>
      <td>32.639921</td>
    </tr>
    <tr>
      <th>31</th>
      <td>-1.109964</td>
      <td>-1.608535</td>
      <td>1.161472</td>
      <td>-0.930096</td>
      <td>0.289342</td>
      <td>0.748811</td>
      <td>-0.442141</td>
      <td>-0.922008</td>
      <td>-0.503747</td>
      <td>0.620862</td>
      <td>1.456842</td>
      <td>0.507872</td>
      <td>0.225414</td>
      <td>-0.564724</td>
      <td>-0.435519</td>
      <td>-0.30251</td>
      <td>0.0</td>
      <td>26.666537</td>
    </tr>
    <tr>
      <th>35</th>
      <td>0.618803</td>
      <td>-0.536615</td>
      <td>0.015955</td>
      <td>-0.930096</td>
      <td>0.679660</td>
      <td>0.748811</td>
      <td>-0.226588</td>
      <td>0.964154</td>
      <td>-0.503755</td>
      <td>2.987311</td>
      <td>0.137625</td>
      <td>1.255052</td>
      <td>0.225414</td>
      <td>1.301665</td>
      <td>0.732818</td>
      <td>-0.30251</td>
      <td>0.0</td>
      <td>47.323516</td>
    </tr>
    <tr>
      <th>39</th>
      <td>-0.640120</td>
      <td>-1.504800</td>
      <td>0.791565</td>
      <td>1.039759</td>
      <td>-0.174037</td>
      <td>-1.335451</td>
      <td>-0.171737</td>
      <td>-0.948736</td>
      <td>0.224512</td>
      <td>-0.146779</td>
      <td>0.909097</td>
      <td>0.960135</td>
      <td>0.225414</td>
      <td>-0.387087</td>
      <td>-0.537519</td>
      <td>3.30568</td>
      <td>0.0</td>
      <td>30.326756</td>
    </tr>
    <tr>
      <th>44</th>
      <td>-0.153820</td>
      <td>0.690906</td>
      <td>1.089877</td>
      <td>1.321167</td>
      <td>1.089435</td>
      <td>-1.335451</td>
      <td>-0.371894</td>
      <td>-0.712020</td>
      <td>-0.502865</td>
      <td>-0.559716</td>
      <td>1.032532</td>
      <td>-0.741700</td>
      <td>0.225414</td>
      <td>-1.125621</td>
      <td>-1.740603</td>
      <td>-0.30251</td>
      <td>0.0</td>
      <td>0.035403</td>
    </tr>
    <tr>
      <th>53</th>
      <td>-0.322118</td>
      <td>0.541068</td>
      <td>0.680196</td>
      <td>-0.930096</td>
      <td>0.118801</td>
      <td>0.748811</td>
      <td>-0.021620</td>
      <td>-0.939341</td>
      <td>-0.496246</td>
      <td>0.679096</td>
      <td>1.194541</td>
      <td>1.099043</td>
      <td>0.225414</td>
      <td>-1.169991</td>
      <td>0.084946</td>
      <td>-0.30251</td>
      <td>68.0</td>
      <td>23.561989</td>
    </tr>
    <tr>
      <th>61</th>
      <td>0.868382</td>
      <td>1.941479</td>
      <td>0.513141</td>
      <td>-1.211504</td>
      <td>0.467824</td>
      <td>0.748811</td>
      <td>-0.339176</td>
      <td>-0.914545</td>
      <td>1.671336</td>
      <td>-0.480305</td>
      <td>1.371980</td>
      <td>-0.105520</td>
      <td>0.225414</td>
      <td>0.110436</td>
      <td>-0.799059</td>
      <td>-0.30251</td>
      <td>62.0</td>
      <td>17.432511</td>
    </tr>
    <tr>
      <th>70</th>
      <td>-0.102579</td>
      <td>-0.721031</td>
      <td>-0.990349</td>
      <td>0.195536</td>
      <td>-0.701542</td>
      <td>0.748811</td>
      <td>-0.503727</td>
      <td>-0.034930</td>
      <td>-0.503669</td>
      <td>3.903185</td>
      <td>-0.440979</td>
      <td>-1.376575</td>
      <td>-2.062984</td>
      <td>-1.501638</td>
      <td>-0.874302</td>
      <td>-0.30251</td>
      <td>55.0</td>
      <td>20.191181</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/27ed137d3c3f3119f18aeac83845870d87929e02.png" /></p>
</div>
</div>
<div id="38a7a7ca" class="cell markdown">
<p>This scatter looks much closer to the desired y = x line than the
neural network. What's also interesting to note is that songs with 0
actual popularity have high variety in predicted popularity, which
suggests that many of those songs have the characteristics of highly
popular songs, according to this algorithm.</p>
</div>
<div id="e1492fbd" class="cell code" data-execution_count="124">
<div class="sourceCode" id="cb75"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Coefficient of Determination&quot;</span>, neigh.score(X_test, y_test))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Coefficient of Determination 0.702356448358433
</code></pre>
</div>
</div>
<div id="607ca4a4" class="cell markdown">
<p>As we can see, the coefficient of determination is also much better
than the Neural Network approach. This suggests that finding songs with
similar characteristics is a better indicator of popularity.</p>
</div>
<div id="39b5f2db" class="cell code">
<div class="sourceCode" id="cb77"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Coefficient of Determination&quot;</span>, neigh.score(X_test, y_test))</span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;RMSE &quot;</span>, ((<span class="op">-</span><span class="dv">1</span>) <span class="op">*</span> (neigh.score(X_test, y_test) <span class="op">-</span> <span class="dv">1</span>) <span class="op">*</span> spotify_df[<span class="st">&#39;popularity&#39;</span>].var()) <span class="op">**</span> <span class="fl">0.5</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Coefficient of Determination 0.702356448358433
RMSE  12.157339887336805
</code></pre>
</div>
</div>
<div id="f1101cea" class="cell markdown">
<h3 id="random-forest">Random Forest</h3>
</div>
<div id="e42d9e6f" class="cell markdown">
<p>Another model option that we can try for our popularity prediction is
a Random Forest model to it's interprebility.</p>
<p>Additional Reading on Random Forest &amp; Resources:</p>
<ul>
<li><a
href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html">Sci-kit
learn</a></li>
<li><a
href="https://www.geeksforgeeks.org/random-forest-regression-in-python/">GeeksforGeeks</a></li>
<li><a
href="https://www.youtube.com/watch?v=gkXX4h3qYm4&amp;pp=0gcJCfwAo7VqN5tD">Youtube
Video for Theory</a></li>
</ul>
</div>
<div id="b2b341be" class="cell code">
<div class="sourceCode" id="cb79"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, r2_score</span></code></pre></div>
</div>
<div id="c9644687" class="cell markdown">
<p>Looking back at our dataset we need to first identify which
categories (columns) would give useful and usable information for our
RandomForest model. Looking at the Spotify dataset these look like good
candidates:</p>
<ul>
<li>duration_ms</li>
<li>explicit</li>
<li>danceability</li>
<li>energy</li>
<li>key</li>
<li>loudness</li>
<li>mode</li>
<li>speechiness</li>
<li>acousticness</li>
<li>instrumentalness</li>
<li>liveness</li>
<li>valence</li>
<li>tempo</li>
<li>time_signature</li>
<li>track_genre_target_enc</li>
</ul>
</div>
<div id="eecb6bd4" class="cell code" data-execution_count="17">
<div class="sourceCode" id="cb80"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>spotify_df.dtypes</span></code></pre></div>
<div class="output execute_result" data-execution_count="17">
<pre><code>track_id                   object
artists                    object
album_name                 object
track_name                 object
popularity                  int64
duration_ms                 int64
explicit                     bool
danceability              float64
energy                    float64
key                         int64
loudness                  float64
mode                        int64
speechiness               float64
acousticness              float64
instrumentalness          float64
liveness                  float64
valence                   float64
tempo                     float64
time_signature              int64
track_genre                object
track_genre_freq            int64
track_genre_target_enc    float64
dtype: object</code></pre>
</div>
</div>
<div id="dc4f6ff4" class="cell code" data-execution_count="20">
<div class="sourceCode" id="cb82"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Select features and target</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>feature_cols <span class="op">=</span> [</span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;duration_ms&#39;</span>, <span class="st">&#39;explicit&#39;</span>, <span class="st">&#39;danceability&#39;</span>, <span class="st">&#39;energy&#39;</span>, <span class="st">&#39;key&#39;</span>,</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;loudness&#39;</span>, <span class="st">&#39;mode&#39;</span>, <span class="st">&#39;speechiness&#39;</span>, <span class="st">&#39;acousticness&#39;</span>, <span class="st">&#39;instrumentalness&#39;</span>,</span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;liveness&#39;</span>, <span class="st">&#39;valence&#39;</span>, <span class="st">&#39;tempo&#39;</span>, <span class="st">&#39;time_signature&#39;</span>, <span class="st">&#39;track_genre_target_enc&#39;</span></span>
<span id="cb82-6"><a href="#cb82-6" aria-hidden="true" tabindex="-1"></a>]</span></code></pre></div>
</div>
<div id="855aa11b" class="cell code" data-execution_count="20">
<div class="sourceCode" id="cb83"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extracting data into X and y</span></span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> spotify_df[feature_cols]</span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> spotify_df[<span class="st">&#39;popularity&#39;</span>]</span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert boolean to integer if needed</span></span>
<span id="cb83-6"><a href="#cb83-6" aria-hidden="true" tabindex="-1"></a>X[<span class="st">&#39;explicit&#39;</span>] <span class="op">=</span> X[<span class="st">&#39;explicit&#39;</span>].astype(<span class="bu">int</span>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>C:\Users\mail2\AppData\Local\Temp\ipykernel_21656\738643166.py:6: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X[&#39;explicit&#39;] = X[&#39;explicit&#39;].astype(int)
</code></pre>
</div>
</div>
<div id="ae53a078" class="cell code" data-execution_count="23">
<div class="sourceCode" id="cb85"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data</span></span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span></code></pre></div>
</div>
<div id="3c405e66" class="cell code" data-execution_count="30">
<div class="sourceCode" id="cb86"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>model.fit(X_train, y_train)</span></code></pre></div>
<div class="output execute_result" data-execution_count="30">
<style>#sk-container-id-3 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-3 {
  color: var(--sklearn-color-text);
}

#sk-container-id-3 pre {
  padding: 0;
}

#sk-container-id-3 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-3 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-3 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-3 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-3 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-3 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-3 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-3 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-3 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-3 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-3 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-3 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-3 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-3 div.sk-label label.sk-toggleable__label,
#sk-container-id-3 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-3 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-3 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-3 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-3 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-3 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-3 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-3 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-3 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-3" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>RandomForestRegressor(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" checked><label for="sk-estimator-id-3" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;RandomForestRegressor<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestRegressor.html">?<span>Documentation for RandomForestRegressor</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>RandomForestRegressor(random_state=42)</pre></div> </div></div></div></div>
</div>
</div>
<div id="37561d2a" class="cell code" data-execution_count="31">
<div class="sourceCode" id="cb87"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict and evaluate</span></span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> model.predict(X_test)</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>rmse <span class="op">=</span> mean_squared_error(y_test, y_pred, squared<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a>r2 <span class="op">=</span> r2_score(y_test, y_pred)</span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-6"><a href="#cb87-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;RMSE: </span><span class="sc">{</span>rmse<span class="sc">:.2f}</span><span class="ss">&quot;</span>)</span>
<span id="cb87-7"><a href="#cb87-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;R²: </span><span class="sc">{</span>r2<span class="sc">:.2f}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>RMSE: 16.13
R²: 0.48
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>c:\Users\mail2\anaconda3\envs\MindLabs\Lib\site-packages\sklearn\metrics\_regression.py:492: FutureWarning: &#39;squared&#39; is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function&#39;root_mean_squared_error&#39;.
  warnings.warn(
</code></pre>
</div>
</div>
<div id="f0fc7992" class="cell markdown">
<p>The results from the Random Forest model isn't very strong. The R
squared value is 0.48 which is in the okay/acceptable range. Since
popularity ranges from 0 to 100, an RMSE of 16.13 means you're off by
~16 units on average. Which even considering the large range is poor
performance from the model. Below you can see the importance the model
gave for each feature. A probable reason for the high error from the
model could be because of the imbalance in the dataset with most of the
songs with low popularity scores. A potential fix or step to take could
be to change from a regression task to a classification task where the
popularity of the song is group into low, medium, or high and the
prediction is one of the 3 categories.</p>
</div>
<div id="d937c5b5" class="cell code" data-execution_count="32">
<div class="sourceCode" id="cb90"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>importances <span class="op">=</span> model.feature_importances_</span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> X.columns</span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>sorted_idx <span class="op">=</span> importances.argsort()</span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a>sns.barplot(x<span class="op">=</span>importances[sorted_idx], y<span class="op">=</span>features[sorted_idx])</span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Feature Importances&quot;</span>)</span>
<span id="cb90-8"><a href="#cb90-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/f24a798268331390d3c12374de7d954091ef6414.png" /></p>
</div>
</div>
<div id="e5e9601e" class="cell markdown">
<p>Below I am creating the popularity classes.</p>
</div>
<div id="f8c5df06" class="cell code" data-execution_count="18">
<div class="sourceCode" id="cb91"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>spotify_df[<span class="st">&#39;popularity_class&#39;</span>] <span class="op">=</span> pd.qcut(</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>    spotify_df[<span class="st">&#39;popularity&#39;</span>],</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>    q<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a>    labels<span class="op">=</span>[<span class="st">&#39;low&#39;</span>, <span class="st">&#39;medium&#39;</span>, <span class="st">&#39;high&#39;</span>]</span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div id="566012df" class="cell code" data-execution_count="21">
<div class="sourceCode" id="cb92"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> spotify_df[feature_cols]</span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> spotify_df[<span class="st">&#39;popularity_class&#39;</span>]</span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>X[<span class="st">&#39;explicit&#39;</span>] <span class="op">=</span> X[<span class="st">&#39;explicit&#39;</span>].astype(<span class="bu">int</span>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>C:\Users\mail2\AppData\Local\Temp\ipykernel_45916\2951831378.py:3: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X[&#39;explicit&#39;] = X[&#39;explicit&#39;].astype(int)
</code></pre>
</div>
</div>
<div id="dbbab3c9" class="cell code" data-execution_count="24">
<div class="sourceCode" id="cb94"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, stratify<span class="op">=</span>y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span></code></pre></div>
</div>
<div id="d57e6859" class="cell code" data-execution_count="25">
<div class="sourceCode" id="cb95"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train classifier</span></span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a>clf.fit(X_train, y_train)</span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> clf.predict(X_test)</span></code></pre></div>
</div>
<div id="f2f6638c" class="cell code" data-execution_count="27">
<div class="sourceCode" id="cb96"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-3"><a href="#cb96-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the classification report as a dictionary</span></span>
<span id="cb96-4"><a href="#cb96-4" aria-hidden="true" tabindex="-1"></a>report_dict <span class="op">=</span> classification_report(</span>
<span id="cb96-5"><a href="#cb96-5" aria-hidden="true" tabindex="-1"></a>    y_test, y_pred, target_names<span class="op">=</span>[<span class="st">&#39;low&#39;</span>, <span class="st">&#39;medium&#39;</span>, <span class="st">&#39;high&#39;</span>], output_dict<span class="op">=</span><span class="va">True</span></span>
<span id="cb96-6"><a href="#cb96-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb96-7"><a href="#cb96-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-8"><a href="#cb96-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to DataFrame and drop &#39;accuracy&#39;, &#39;macro avg&#39;, &#39;weighted avg&#39; rows if you only want per-class</span></span>
<span id="cb96-9"><a href="#cb96-9" aria-hidden="true" tabindex="-1"></a>report_df <span class="op">=</span> pd.DataFrame(report_dict).transpose().<span class="bu">round</span>(<span class="dv">2</span>)</span>
<span id="cb96-10"><a href="#cb96-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-11"><a href="#cb96-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Optionally drop support column if you just want metrics</span></span>
<span id="cb96-12"><a href="#cb96-12" aria-hidden="true" tabindex="-1"></a>metrics_to_plot <span class="op">=</span> report_df.drop([<span class="st">&#39;accuracy&#39;</span>, <span class="st">&#39;macro avg&#39;</span>, <span class="st">&#39;weighted avg&#39;</span>], errors<span class="op">=</span><span class="st">&#39;ignore&#39;</span>)[[<span class="st">&#39;precision&#39;</span>, <span class="st">&#39;recall&#39;</span>, <span class="st">&#39;f1-score&#39;</span>]]</span>
<span id="cb96-13"><a href="#cb96-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-14"><a href="#cb96-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the heatmap</span></span>
<span id="cb96-15"><a href="#cb96-15" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">4</span>))</span>
<span id="cb96-16"><a href="#cb96-16" aria-hidden="true" tabindex="-1"></a>sns.heatmap(metrics_to_plot, annot<span class="op">=</span><span class="va">True</span>, cmap<span class="op">=</span><span class="st">&#39;YlGnBu&#39;</span>, fmt<span class="op">=</span><span class="st">&#39;.2f&#39;</span>, cbar<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb96-17"><a href="#cb96-17" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Classification Report Heatmap&quot;</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb96-18"><a href="#cb96-18" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Metrics&quot;</span>)</span>
<span id="cb96-19"><a href="#cb96-19" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;Classes&quot;</span>)</span>
<span id="cb96-20"><a href="#cb96-20" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb96-21"><a href="#cb96-21" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/561e5f0bb51e7c5559befc43d96e8301fbfc93c6.png" /></p>
</div>
</div>
<div id="47fb9fd6" class="cell markdown">
<h3 id="-class-wise-interpretation">🧠 Class-wise Interpretation</h3>
<ul>
<li><strong>Low Popularity:</strong>
<ul>
<li>Precision: <strong>0.73</strong> → When the model predicts "low",
it's correct 73% of the time.</li>
<li>Recall: <strong>0.71</strong> → It identifies 71% of actual "low"
popularity songs.</li>
<li>F1-score: <strong>0.72</strong> → Balanced performance.</li>
</ul></li>
<li><strong>Medium Popularity:</strong>
<ul>
<li>Precision: <strong>0.78</strong>, Recall: <strong>0.80</strong>,
F1-score: <strong>0.79</strong></li>
<li>This class has the <strong>strongest performance</strong>
overall.</li>
</ul></li>
<li><strong>High Popularity:</strong>
<ul>
<li>Precision: <strong>0.69</strong>, Recall: <strong>0.68</strong>,
F1-score: <strong>0.68</strong></li>
<li>Slightly weaker, which is expected — hit songs are more
nuanced.</li>
</ul></li>
</ul>
</div>
<div id="69b52dd1" class="cell markdown">
<h3 id="-overall-model-performance">📈 Overall Model Performance</h3>
<ul>
<li><strong>Accuracy</strong>: <strong>0.73</strong> → 73% of all
predictions were correct.</li>
<li><strong>Macro Avg</strong>: <strong>0.73</strong> → Average score
<strong>treating all classes equally</strong>.</li>
<li><strong>Weighted Avg</strong>: <strong>0.73</strong> → Average
<strong>weighted by class size</strong>.</li>
</ul>
</div>
<div id="8c830255" class="cell markdown">
<h2 id="v--insights-and-conclusions">V. 🧠 Insights and Conclusions</h2>
</div>
<div id="3a73a293" class="cell markdown">
<p>What we might conclude from this exploration is that a song’s
<strong>popularity</strong> cannot be judged straightforwardly from just
one or two features like<br />
🎵 tempo, ⚡ energy, 🎻 instrumentals, or even 🔞 explicitness.</p>
<p>➡️ What matters most is the <strong>combination</strong> of all these
numeric features —<br />
<strong>plus</strong> some key factors like:</p>
<ul>
<li>🎼 <strong>Genre</strong></li>
<li>👤 <strong>Artist</strong></li>
</ul>
<p>These two elements play a <strong>huge role</strong> in determining
how popular a song becomes.</p>
<p>🎤 As expected, the <strong>artist</strong> really knows best what
makes a hit — and that human creativity can’t be fully replaced by
numbers.<br />
Still, our model gives us an exciting way to explore what <em>might</em>
make the next viral song!</p>
</div>
<div id="420305ad" class="cell markdown">
<h3 id="work-for-the-other-models-for-reference">Work for the other
models for reference</h3>
</div>
<div id="9b28f62b" class="cell markdown">
<h3 id="neural-network-section">Neural Network Section</h3>
<p>Credits:</p>
<ul>
<li>HW4</li>
<li><a
href="https://www.geeksforgeeks.org/deep-learning/how-to-implement-neural-networks-in-pytorch/"
class="uri">https://www.geeksforgeeks.org/deep-learning/how-to-implement-neural-networks-in-pytorch/</a></li>
<li><a
href="https://docs.pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html"
class="uri">https://docs.pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html</a></li>
<li><a
href="https://docs.pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html"
class="uri">https://docs.pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html</a></li>
<li><a
href="https://stackoverflow.com/questions/42966393/is-it-good-learning-rate-for-adam-method"
class="uri">https://stackoverflow.com/questions/42966393/is-it-good-learning-rate-for-adam-method</a></li>
<li><a
href="https://colab.research.google.com/drive/188oDAlTSCycppp_ijjLFuyVwsWYLh1Mm?usp=sharing#scrollTo=2vsxhmnqwBtd"
class="uri">https://colab.research.google.com/drive/188oDAlTSCycppp_ijjLFuyVwsWYLh1Mm?usp=sharing#scrollTo=2vsxhmnqwBtd</a></li>
</ul>
</div>
<div id="392c5325" class="cell code">
<div class="sourceCode" id="cb97"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb97-3"><a href="#cb97-3" aria-hidden="true" tabindex="-1"></a><span class="co">#from sklearn.preprocessing import MinMaxScaler</span></span>
<span id="cb97-4"><a href="#cb97-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, TensorDataset</span>
<span id="cb97-5"><a href="#cb97-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-6"><a href="#cb97-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb97-7"><a href="#cb97-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb97-8"><a href="#cb97-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb97-9"><a href="#cb97-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb97-10"><a href="#cb97-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.optim.lr_scheduler <span class="im">import</span> StepLR</span>
<span id="cb97-11"><a href="#cb97-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-12"><a href="#cb97-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb97-13"><a href="#cb97-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span></code></pre></div>
</div>
<div id="612ed625" class="cell code">
<div class="sourceCode" id="cb98"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>artists_popularity_map <span class="op">=</span> spotify_df.groupby(<span class="st">&#39;artists&#39;</span>)[<span class="st">&#39;popularity&#39;</span>].mean()</span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>spotify_df[<span class="st">&#39;artists_target_enc&#39;</span>] <span class="op">=</span> spotify_df[<span class="st">&#39;artists&#39;</span>].<span class="bu">map</span>(artists_popularity_map)</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a><span class="co">#encode explicit as 1 or 0</span></span>
<span id="cb98-5"><a href="#cb98-5" aria-hidden="true" tabindex="-1"></a>spotify_df[<span class="st">&#39;explicit_enc&#39;</span>] <span class="op">=</span> spotify_df[<span class="st">&#39;explicit&#39;</span>].<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x <span class="cf">else</span> <span class="dv">0</span>)</span>
<span id="cb98-6"><a href="#cb98-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-7"><a href="#cb98-7" aria-hidden="true" tabindex="-1"></a><span class="co">#drop non-numeric columns</span></span>
<span id="cb98-8"><a href="#cb98-8" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> spotify_df.drop(columns<span class="op">=</span>[<span class="st">&#39;popularity&#39;</span>, <span class="st">&#39;artists&#39;</span>, <span class="st">&#39;track_id&#39;</span>, <span class="st">&#39;album_name&#39;</span>, <span class="st">&#39;track_name&#39;</span>, <span class="st">&#39;explicit&#39;</span>, <span class="st">&#39;track_genre&#39;</span>, <span class="st">&#39;track_genre_freq&#39;</span>])</span>
<span id="cb98-9"><a href="#cb98-9" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> spotify_df[<span class="st">&#39;popularity&#39;</span>]</span>
<span id="cb98-10"><a href="#cb98-10" aria-hidden="true" tabindex="-1"></a>display(X.head())</span>
<span id="cb98-11"><a href="#cb98-11" aria-hidden="true" tabindex="-1"></a>display(y.head())</span>
<span id="cb98-12"><a href="#cb98-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-13"><a href="#cb98-13" aria-hidden="true" tabindex="-1"></a>display(X.dtypes)</span>
<span id="cb98-14"><a href="#cb98-14" aria-hidden="true" tabindex="-1"></a>display(y.dtypes)</span>
<span id="cb98-15"><a href="#cb98-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-16"><a href="#cb98-16" aria-hidden="true" tabindex="-1"></a><span class="co">#Convert type of data into floats</span></span>
<span id="cb98-17"><a href="#cb98-17" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> X.astype(<span class="st">&#39;float32&#39;</span>)</span>
<span id="cb98-18"><a href="#cb98-18" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> y.astype(<span class="st">&#39;float32&#39;</span>)</span>
<span id="cb98-19"><a href="#cb98-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-20"><a href="#cb98-20" aria-hidden="true" tabindex="-1"></a>display(X.dtypes)</span>
<span id="cb98-21"><a href="#cb98-21" aria-hidden="true" tabindex="-1"></a>display(y.dtypes)</span>
<span id="cb98-22"><a href="#cb98-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-23"><a href="#cb98-23" aria-hidden="true" tabindex="-1"></a>random_state<span class="op">=</span> <span class="dv">42</span></span>
<span id="cb98-24"><a href="#cb98-24" aria-hidden="true" tabindex="-1"></a><span class="co">#Credit: HW4</span></span>
<span id="cb98-25"><a href="#cb98-25" aria-hidden="true" tabindex="-1"></a><span class="co">#split into train and test data</span></span>
<span id="cb98-26"><a href="#cb98-26" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span>random_state)</span>
<span id="cb98-27"><a href="#cb98-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-28"><a href="#cb98-28" aria-hidden="true" tabindex="-1"></a><span class="co">#Normalize</span></span>
<span id="cb98-29"><a href="#cb98-29" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb98-30"><a href="#cb98-30" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb98-31"><a href="#cb98-31" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> scaler.fit_transform(X_test)</span>
<span id="cb98-32"><a href="#cb98-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-33"><a href="#cb98-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to PyTorch tensors</span></span>
<span id="cb98-34"><a href="#cb98-34" aria-hidden="true" tabindex="-1"></a>X_train_tensor <span class="op">=</span> torch.tensor(X_train)</span>
<span id="cb98-35"><a href="#cb98-35" aria-hidden="true" tabindex="-1"></a>y_train_tensor <span class="op">=</span> torch.tensor(y_train.values)</span>
<span id="cb98-36"><a href="#cb98-36" aria-hidden="true" tabindex="-1"></a>X_test_tensor <span class="op">=</span> torch.tensor(X_test)</span>
<span id="cb98-37"><a href="#cb98-37" aria-hidden="true" tabindex="-1"></a>y_test_tensor <span class="op">=</span> torch.tensor(y_test.values)</span>
<span id="cb98-38"><a href="#cb98-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-39"><a href="#cb98-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Create data loaders</span></span>
<span id="cb98-40"><a href="#cb98-40" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> TensorDataset(X_train_tensor, y_train_tensor)</span>
<span id="cb98-41"><a href="#cb98-41" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> TensorDataset(X_test_tensor, y_test_tensor)</span>
<span id="cb98-42"><a href="#cb98-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-43"><a href="#cb98-43" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb98-44"><a href="#cb98-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-45"><a href="#cb98-45" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(train_dataset, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb98-46"><a href="#cb98-46" aria-hidden="true" tabindex="-1"></a>test_loader <span class="op">=</span> DataLoader(test_dataset, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb98-47"><a href="#cb98-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-48"><a href="#cb98-48" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> train_loader.batch_size</span>
<span id="cb98-49"><a href="#cb98-49" aria-hidden="true" tabindex="-1"></a>num_train_data <span class="op">=</span> <span class="bu">len</span>(train_loader) <span class="op">*</span> batch_size</span>
<span id="cb98-50"><a href="#cb98-50" aria-hidden="true" tabindex="-1"></a>num_test_data <span class="op">=</span> <span class="bu">len</span>(test_loader) <span class="op">*</span> batch_size</span>
<span id="cb98-51"><a href="#cb98-51" aria-hidden="true" tabindex="-1"></a>feat_dim <span class="op">=</span> train_loader.dataset[<span class="dv">0</span>][<span class="dv">0</span>].shape[<span class="dv">0</span>]</span></code></pre></div>
<div class="output display_data">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>duration_ms</th>
      <th>danceability</th>
      <th>energy</th>
      <th>key</th>
      <th>loudness</th>
      <th>mode</th>
      <th>speechiness</th>
      <th>acousticness</th>
      <th>instrumentalness</th>
      <th>liveness</th>
      <th>valence</th>
      <th>tempo</th>
      <th>time_signature</th>
      <th>track_genre_target_enc</th>
      <th>artists_target_enc</th>
      <th>explicit_enc</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>230666</td>
      <td>0.676</td>
      <td>0.4610</td>
      <td>1</td>
      <td>-6.746</td>
      <td>0</td>
      <td>0.1430</td>
      <td>0.0322</td>
      <td>0.000001</td>
      <td>0.3580</td>
      <td>0.715</td>
      <td>87.917</td>
      <td>4</td>
      <td>42.483</td>
      <td>58.000000</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>149610</td>
      <td>0.420</td>
      <td>0.1660</td>
      <td>1</td>
      <td>-17.235</td>
      <td>1</td>
      <td>0.0763</td>
      <td>0.9240</td>
      <td>0.000006</td>
      <td>0.1010</td>
      <td>0.267</td>
      <td>77.489</td>
      <td>4</td>
      <td>42.483</td>
      <td>42.923077</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>210826</td>
      <td>0.438</td>
      <td>0.3590</td>
      <td>0</td>
      <td>-9.734</td>
      <td>1</td>
      <td>0.0557</td>
      <td>0.2100</td>
      <td>0.000000</td>
      <td>0.1170</td>
      <td>0.120</td>
      <td>76.332</td>
      <td>4</td>
      <td>42.483</td>
      <td>57.000000</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>201933</td>
      <td>0.266</td>
      <td>0.0596</td>
      <td>0</td>
      <td>-18.515</td>
      <td>1</td>
      <td>0.0363</td>
      <td>0.9050</td>
      <td>0.000071</td>
      <td>0.1320</td>
      <td>0.143</td>
      <td>181.740</td>
      <td>3</td>
      <td>42.483</td>
      <td>53.933333</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>198853</td>
      <td>0.618</td>
      <td>0.4430</td>
      <td>2</td>
      <td>-9.681</td>
      <td>1</td>
      <td>0.0526</td>
      <td>0.4690</td>
      <td>0.000000</td>
      <td>0.0829</td>
      <td>0.167</td>
      <td>119.949</td>
      <td>4</td>
      <td>42.483</td>
      <td>41.727273</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="output display_data">
<pre><code>0    73
1    55
2    57
3    71
4    82
Name: popularity, dtype: int64</code></pre>
</div>
<div class="output display_data">
<pre><code>duration_ms                 int64
danceability              float64
energy                    float64
key                         int64
loudness                  float64
mode                        int64
speechiness               float64
acousticness              float64
instrumentalness          float64
liveness                  float64
valence                   float64
tempo                     float64
time_signature              int64
track_genre_target_enc    float64
artists_target_enc        float64
explicit_enc                int64
dtype: object</code></pre>
</div>
<div class="output display_data">
<pre><code>dtype(&#39;int64&#39;)</code></pre>
</div>
<div class="output display_data">
<pre><code>duration_ms               float32
danceability              float32
energy                    float32
key                       float32
loudness                  float32
mode                      float32
speechiness               float32
acousticness              float32
instrumentalness          float32
liveness                  float32
valence                   float32
tempo                     float32
time_signature            float32
track_genre_target_enc    float32
artists_target_enc        float32
explicit_enc              float32
dtype: object</code></pre>
</div>
<div class="output display_data">
<pre><code>dtype(&#39;float32&#39;)</code></pre>
</div>
</div>
<div id="e9394afd" class="cell code">
<div class="sourceCode" id="cb104"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span>(<span class="bu">type</span>(train_loader) <span class="op">==</span> DataLoader)</span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span>(<span class="bu">type</span>(test_loader) <span class="op">==</span> DataLoader)</span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span>:</span>
<span id="cb104-5"><a href="#cb104-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&#39;&quot;train_loader&quot; and &quot;test_loader&quot; must be DataLoader type!&#39;</span>)</span>
<span id="cb104-6"><a href="#cb104-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-7"><a href="#cb104-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Batch Size:&quot;</span>, batch_size)</span>
<span id="cb104-8"><a href="#cb104-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Number of Train Data:&quot;</span>, num_train_data)</span>
<span id="cb104-9"><a href="#cb104-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Number of Test Data:&quot;</span>, num_test_data)</span>
<span id="cb104-10"><a href="#cb104-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Feature Dimension:&quot;</span>, feat_dim)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Batch Size: 128
Number of Train Data: 90880
Number of Test Data: 22784
Feature Dimension: 16
</code></pre>
</div>
</div>
<div id="8ad31ab0" class="cell code">
<div class="sourceCode" id="cb106"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> (</span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;cuda&quot;</span></span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> torch.cuda.is_available()</span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span> <span class="st">&quot;mps&quot;</span></span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> torch.backends.mps.is_available()</span>
<span id="cb106-6"><a href="#cb106-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span></span>
<span id="cb106-7"><a href="#cb106-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb106-8"><a href="#cb106-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Using </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss"> device&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Using mps device
</code></pre>
</div>
</div>
<div id="d678cbc6" class="cell code">
<div class="sourceCode" id="cb108"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NeuralNetwork(nn.Module):</span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, feat_dim):</span>
<span id="cb108-3"><a href="#cb108-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb108-4"><a href="#cb108-4" aria-hidden="true" tabindex="-1"></a>        <span class="co">### 3-layer fully connected neural network.</span></span>
<span id="cb108-5"><a href="#cb108-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear_relu_stack <span class="op">=</span> nn.Sequential(</span>
<span id="cb108-6"><a href="#cb108-6" aria-hidden="true" tabindex="-1"></a>            nn.Linear(feat_dim, <span class="dv">1024</span>, dtype<span class="op">=</span> torch.float32),</span>
<span id="cb108-7"><a href="#cb108-7" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb108-8"><a href="#cb108-8" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">1024</span>, <span class="dv">512</span>, dtype<span class="op">=</span> torch.float32),</span>
<span id="cb108-9"><a href="#cb108-9" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb108-10"><a href="#cb108-10" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">512</span>, <span class="dv">1</span>, dtype<span class="op">=</span> torch.float32),</span>
<span id="cb108-11"><a href="#cb108-11" aria-hidden="true" tabindex="-1"></a>            <span class="co">#nn.Sigmoid()</span></span>
<span id="cb108-12"><a href="#cb108-12" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb108-13"><a href="#cb108-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-14"><a href="#cb108-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb108-15"><a href="#cb108-15" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> <span class="va">self</span>.linear_relu_stack(x)</span>
<span id="cb108-16"><a href="#cb108-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> logits</span>
<span id="cb108-17"><a href="#cb108-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-18"><a href="#cb108-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Instantiate the model</span></span>
<span id="cb108-19"><a href="#cb108-19" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> NeuralNetwork(feat_dim<span class="op">=</span>feat_dim).to(device)</span>
<span id="cb108-20"><a href="#cb108-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>NeuralNetwork(
  (linear_relu_stack): Sequential(
    (0): Linear(in_features=16, out_features=1024, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1024, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=1, bias=True)
  )
)
</code></pre>
</div>
</div>
<div id="aa461efc" class="cell code">
<div class="sourceCode" id="cb110"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> nn.MSELoss()</span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span> <span class="fl">5e-7</span>)</span>
<span id="cb110-3"><a href="#cb110-3" aria-hidden="true" tabindex="-1"></a>scheduler <span class="op">=</span> StepLR(optimizer, step_size<span class="op">=</span><span class="dv">20</span>, gamma<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb110-4"><a href="#cb110-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb110-5"><a href="#cb110-5" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb110-6"><a href="#cb110-6" aria-hidden="true" tabindex="-1"></a>avg_losses <span class="op">=</span> []</span>
<span id="cb110-7"><a href="#cb110-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb110-8"><a href="#cb110-8" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb110-9"><a href="#cb110-9" aria-hidden="true" tabindex="-1"></a>    running_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb110-10"><a href="#cb110-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch_idx, (data, targets) <span class="kw">in</span> <span class="bu">enumerate</span>(train_loader):</span>
<span id="cb110-11"><a href="#cb110-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Forward pass</span></span>
<span id="cb110-12"><a href="#cb110-12" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb110-13"><a href="#cb110-13" aria-hidden="true" tabindex="-1"></a>        data, targets <span class="op">=</span> data.to(device), targets.to(device)</span>
<span id="cb110-14"><a href="#cb110-14" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> model(data)</span>
<span id="cb110-15"><a href="#cb110-15" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(pred, targets)</span>
<span id="cb110-16"><a href="#cb110-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Backward pass</span></span>
<span id="cb110-17"><a href="#cb110-17" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb110-18"><a href="#cb110-18" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb110-19"><a href="#cb110-19" aria-hidden="true" tabindex="-1"></a>        running_loss <span class="op">+=</span> loss.item() <span class="op">**</span> <span class="fl">0.5</span> <span class="co">#add MSE ** 0.5 for the batch</span></span>
<span id="cb110-20"><a href="#cb110-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb110-21"><a href="#cb110-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">#get the average loss of this epoch over every batch </span></span>
<span id="cb110-22"><a href="#cb110-22" aria-hidden="true" tabindex="-1"></a>    <span class="co">#len(train_loader) is the number of iterations or batches in the epoch</span></span>
<span id="cb110-23"><a href="#cb110-23" aria-hidden="true" tabindex="-1"></a>    avg_losses.append(running_loss <span class="op">/</span> <span class="bu">len</span>(train_loader))</span>
<span id="cb110-24"><a href="#cb110-24" aria-hidden="true" tabindex="-1"></a>    scheduler.step()</span>
<span id="cb110-25"><a href="#cb110-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb110-26"><a href="#cb110-26" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&#39;Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>epochs<span class="sc">}</span><span class="ss">, Average MSE Loss in original units: </span><span class="sc">{</span>avg_losses[<span class="op">-</span><span class="dv">1</span>]<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb110-27"><a href="#cb110-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb110-28"><a href="#cb110-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Finished Training&#39;</span>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([87])) that is different to the input size (torch.Size([87, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Epoch 1/100, Average MSE Loss in original units: 39.92520636839794
Epoch 2/100, Average MSE Loss in original units: 39.50686518096674
Epoch 3/100, Average MSE Loss in original units: 39.05217888917549
Epoch 4/100, Average MSE Loss in original units: 38.56087793677272
Epoch 5/100, Average MSE Loss in original units: 38.07235839347296
Epoch 6/100, Average MSE Loss in original units: 37.580691327247834
Epoch 7/100, Average MSE Loss in original units: 37.088776321011714
Epoch 8/100, Average MSE Loss in original units: 36.60467300129989
Epoch 9/100, Average MSE Loss in original units: 36.11216843774347
Epoch 10/100, Average MSE Loss in original units: 35.61935371054808
Epoch 11/100, Average MSE Loss in original units: 35.11754852204075
Epoch 12/100, Average MSE Loss in original units: 34.613947322476974
Epoch 13/100, Average MSE Loss in original units: 34.10113023973165
Epoch 14/100, Average MSE Loss in original units: 33.57869826697288
Epoch 15/100, Average MSE Loss in original units: 33.06935954887216
Epoch 16/100, Average MSE Loss in original units: 32.549160873178764
Epoch 17/100, Average MSE Loss in original units: 32.02299042641106
Epoch 18/100, Average MSE Loss in original units: 31.507790378209865
Epoch 19/100, Average MSE Loss in original units: 30.985146640796305
Epoch 20/100, Average MSE Loss in original units: 30.475354461395874
Epoch 21/100, Average MSE Loss in original units: 30.09046498954362
Epoch 22/100, Average MSE Loss in original units: 29.83375746973948
Epoch 23/100, Average MSE Loss in original units: 29.585399854512474
Epoch 24/100, Average MSE Loss in original units: 29.332904030094742
Epoch 25/100, Average MSE Loss in original units: 29.081692044774066
Epoch 26/100, Average MSE Loss in original units: 28.843510121167004
Epoch 27/100, Average MSE Loss in original units: 28.59885873931619
Epoch 28/100, Average MSE Loss in original units: 28.356046321282893
Epoch 29/100, Average MSE Loss in original units: 28.117990478980502
Epoch 30/100, Average MSE Loss in original units: 27.88769060661901
Epoch 31/100, Average MSE Loss in original units: 27.66195097483165
Epoch 32/100, Average MSE Loss in original units: 27.436862065079815
Epoch 33/100, Average MSE Loss in original units: 27.223354407607083
Epoch 34/100, Average MSE Loss in original units: 27.004532702980697
Epoch 35/100, Average MSE Loss in original units: 26.803662889542014
Epoch 36/100, Average MSE Loss in original units: 26.60419442634853
Epoch 37/100, Average MSE Loss in original units: 26.40331025616301
Epoch 38/100, Average MSE Loss in original units: 26.215506345024817
Epoch 39/100, Average MSE Loss in original units: 26.033998019237767
Epoch 40/100, Average MSE Loss in original units: 25.859277198161045
Epoch 41/100, Average MSE Loss in original units: 25.737548838015044
Epoch 42/100, Average MSE Loss in original units: 25.644827304417863
Epoch 43/100, Average MSE Loss in original units: 25.567906927014562
Epoch 44/100, Average MSE Loss in original units: 25.491375359734594
Epoch 45/100, Average MSE Loss in original units: 25.411843800771482
Epoch 46/100, Average MSE Loss in original units: 25.336501091073337
Epoch 47/100, Average MSE Loss in original units: 25.265102167132017
Epoch 48/100, Average MSE Loss in original units: 25.192427730523374
Epoch 49/100, Average MSE Loss in original units: 25.111967636897823
Epoch 50/100, Average MSE Loss in original units: 25.05274694251789
Epoch 51/100, Average MSE Loss in original units: 24.986491220470572
Epoch 52/100, Average MSE Loss in original units: 24.92460903355034
Epoch 53/100, Average MSE Loss in original units: 24.85779372011131
Epoch 54/100, Average MSE Loss in original units: 24.802410483419653
Epoch 55/100, Average MSE Loss in original units: 24.74470677288448
Epoch 56/100, Average MSE Loss in original units: 24.68993504147766
Epoch 57/100, Average MSE Loss in original units: 24.636219978374076
Epoch 58/100, Average MSE Loss in original units: 24.58432670458516
Epoch 59/100, Average MSE Loss in original units: 24.538592447322923
Epoch 60/100, Average MSE Loss in original units: 24.48919232471983
Epoch 61/100, Average MSE Loss in original units: 24.458720831369032
Epoch 62/100, Average MSE Loss in original units: 24.43170524370897
Epoch 63/100, Average MSE Loss in original units: 24.408261820494907
Epoch 64/100, Average MSE Loss in original units: 24.38279351241744
Epoch 65/100, Average MSE Loss in original units: 24.367187755006388
Epoch 66/100, Average MSE Loss in original units: 24.34592708132929
Epoch 67/100, Average MSE Loss in original units: 24.32201692581183
Epoch 68/100, Average MSE Loss in original units: 24.301245423231155
Epoch 69/100, Average MSE Loss in original units: 24.286866423825764
Epoch 70/100, Average MSE Loss in original units: 24.26453892518404
Epoch 71/100, Average MSE Loss in original units: 24.250377824354757
Epoch 72/100, Average MSE Loss in original units: 24.22640643253972
Epoch 73/100, Average MSE Loss in original units: 24.217306671073235
Epoch 74/100, Average MSE Loss in original units: 24.195026405639982
Epoch 75/100, Average MSE Loss in original units: 24.18100441059044
Epoch 76/100, Average MSE Loss in original units: 24.15859233125148
Epoch 77/100, Average MSE Loss in original units: 24.145951744885735
Epoch 78/100, Average MSE Loss in original units: 24.119596049336835
Epoch 79/100, Average MSE Loss in original units: 24.111905888842852
Epoch 80/100, Average MSE Loss in original units: 24.097380904017637
Epoch 81/100, Average MSE Loss in original units: 24.080247672727026
Epoch 82/100, Average MSE Loss in original units: 24.079482094928725
Epoch 83/100, Average MSE Loss in original units: 24.068945792325614
Epoch 84/100, Average MSE Loss in original units: 24.056763962203526
Epoch 85/100, Average MSE Loss in original units: 24.05788548925725
Epoch 86/100, Average MSE Loss in original units: 24.049042407991085
Epoch 87/100, Average MSE Loss in original units: 24.039438623204067
Epoch 88/100, Average MSE Loss in original units: 24.04029442534095
Epoch 89/100, Average MSE Loss in original units: 24.02420709041609
Epoch 90/100, Average MSE Loss in original units: 24.019393654402148
Epoch 91/100, Average MSE Loss in original units: 24.01398873077832
Epoch 92/100, Average MSE Loss in original units: 24.008107776343124
Epoch 93/100, Average MSE Loss in original units: 24.00188506096783
Epoch 94/100, Average MSE Loss in original units: 23.996122958773643
Epoch 95/100, Average MSE Loss in original units: 23.983494185770823
Epoch 96/100, Average MSE Loss in original units: 23.979227915414857
Epoch 97/100, Average MSE Loss in original units: 23.969764627942816
Epoch 98/100, Average MSE Loss in original units: 23.965654533243466
Epoch 99/100, Average MSE Loss in original units: 23.961272042122403
Epoch 100/100, Average MSE Loss in original units: 23.955823165180455
Finished Training
</code></pre>
</div>
</div>
<div id="6a469b3d" class="cell code">
<div class="sourceCode" id="cb113"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>test_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> batch_idx, (data, targets) <span class="kw">in</span> <span class="bu">enumerate</span>(test_loader):</span>
<span id="cb113-3"><a href="#cb113-3" aria-hidden="true" tabindex="-1"></a>    data, targets <span class="op">=</span> data.to(device), targets.to(device)</span>
<span id="cb113-4"><a href="#cb113-4" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> criterion(model(data), targets)</span>
<span id="cb113-5"><a href="#cb113-5" aria-hidden="true" tabindex="-1"></a>    test_loss <span class="op">+=</span> loss.item()</span>
<span id="cb113-6"><a href="#cb113-6" aria-hidden="true" tabindex="-1"></a>test_loss <span class="op">=</span> test_loss <span class="op">/</span> <span class="bu">len</span>(test_loader)</span>
<span id="cb113-7"><a href="#cb113-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-8"><a href="#cb113-8" aria-hidden="true" tabindex="-1"></a>train_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb113-9"><a href="#cb113-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> batch_idx, (data, targets) <span class="kw">in</span> <span class="bu">enumerate</span>(train_loader):</span>
<span id="cb113-10"><a href="#cb113-10" aria-hidden="true" tabindex="-1"></a>    data, targets <span class="op">=</span> data.to(device), targets.to(device)</span>
<span id="cb113-11"><a href="#cb113-11" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> criterion(model(data), targets)</span>
<span id="cb113-12"><a href="#cb113-12" aria-hidden="true" tabindex="-1"></a>    train_loss <span class="op">+=</span> loss.item()</span>
<span id="cb113-13"><a href="#cb113-13" aria-hidden="true" tabindex="-1"></a>train_loss <span class="op">=</span> train_loss <span class="op">/</span> <span class="bu">len</span>(train_loader)</span>
<span id="cb113-14"><a href="#cb113-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-15"><a href="#cb113-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Train Loss (in original units square root of average MSE):&quot;</span>, train_loss <span class="op">**</span> <span class="fl">0.5</span>)</span>
<span id="cb113-16"><a href="#cb113-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Loss (in original units square root of average MSE):&quot;</span>, test_loss <span class="op">**</span> <span class="fl">0.5</span>)</span>
<span id="cb113-17"><a href="#cb113-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Coefficient of Determination of Test Data&quot;</span>, <span class="dv">1</span> <span class="op">-</span> test_loss<span class="op">/</span>np.var(y_test))</span>
<span id="cb113-18"><a href="#cb113-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-19"><a href="#cb113-19" aria-hidden="true" tabindex="-1"></a>plt.plot(avg_losses)</span>
<span id="cb113-20"><a href="#cb113-20" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Losses over Time&quot;</span>)</span>
<span id="cb113-21"><a href="#cb113-21" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Epoch&quot;</span>)</span>
<span id="cb113-22"><a href="#cb113-22" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;Loss (MSE)&quot;</span>)</span>
<span id="cb113-23"><a href="#cb113-23" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output stream stderr">
<pre><code>/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([54])) that is different to the input size (torch.Size([54, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Train Loss (in original units square root of average MSE): 23.991617163450787
Test Loss (in original units square root of average MSE): 24.131351592222824
Coefficient of Determination of Test Data -0.1608975
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/acc313f677261005bf8e96cefa22ae06a78071a2.png" /></p>
</div>
</div>
<div id="208ecc0b" class="cell markdown">
<p>We see that the coefficient of determination is negative. This means
that this model is worse at predicting popularity than the mean itself.
Recall the formula for coefficient of determination is <span
class="math display">$$R^{2} = 1-\frac {\sum_{i} (y_{i}-
\hat{y}_{i})^{2}} {\sum_{i} (y_{i}- \bar{y}_{i})^{2}} = 1- \frac
{MSE(y)} {Var(y)}$$</span> We prefer that MSE is low, so our goal is for
this coefficient to be as close to 1 as possible. Therefore, this is a
poor model for predicting popularity.</p>
</div>
<div id="ff497fb3" class="cell code">
<div class="sourceCode" id="cb116"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a>spotify_df[<span class="st">&#39;popularity&#39;</span>].describe()</span></code></pre></div>
<div class="output display_data">
<pre><code>count    113549.000000
mean         33.324433
std          22.283855
min           0.000000
25%          17.000000
50%          35.000000
75%          50.000000
max         100.000000
Name: popularity, dtype: float64</code></pre>
</div>
</div>
<div id="3553ba65" class="cell code">
<div class="sourceCode" id="cb118"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="co">## define code for visualizing the results</span></span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ml_visual(sample, target, preds):</span>
<span id="cb118-3"><a href="#cb118-3" aria-hidden="true" tabindex="-1"></a>    sample_df <span class="op">=</span> pd.DataFrame(sample, columns<span class="op">=</span> X.columns)</span>
<span id="cb118-4"><a href="#cb118-4" aria-hidden="true" tabindex="-1"></a>    target_df <span class="op">=</span> pd.DataFrame(target, columns<span class="op">=</span> [<span class="st">&#39;popularity&#39;</span>])</span>
<span id="cb118-5"><a href="#cb118-5" aria-hidden="true" tabindex="-1"></a>    preds_df <span class="op">=</span> pd.DataFrame(preds, columns<span class="op">=</span> [<span class="st">&#39;predicted_popularity&#39;</span>])</span>
<span id="cb118-6"><a href="#cb118-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb118-7"><a href="#cb118-7" aria-hidden="true" tabindex="-1"></a>    sample_df <span class="op">=</span> sample_df.merge(target_df, left_index<span class="op">=</span><span class="va">True</span>, right_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb118-8"><a href="#cb118-8" aria-hidden="true" tabindex="-1"></a>    sample_df <span class="op">=</span> sample_df.merge(preds_df, left_index<span class="op">=</span><span class="va">True</span>, right_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb118-9"><a href="#cb118-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb118-10"><a href="#cb118-10" aria-hidden="true" tabindex="-1"></a>    display(sample_df.head(<span class="dv">10</span>))</span>
<span id="cb118-11"><a href="#cb118-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb118-12"><a href="#cb118-12" aria-hidden="true" tabindex="-1"></a>    plt.scatter(target, preds)</span>
<span id="cb118-13"><a href="#cb118-13" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">&#39;actual popularity&#39;</span>)</span>
<span id="cb118-14"><a href="#cb118-14" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">&#39;predicted popularity&#39;</span>)</span>
<span id="cb118-15"><a href="#cb118-15" aria-hidden="true" tabindex="-1"></a>    plt.plot(target, target)</span>
<span id="cb118-16"><a href="#cb118-16" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code></pre></div>
</div>
<div id="fecdf47b" class="cell code">
<div class="sourceCode" id="cb119"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Visualize the model accuracy with some predictions</span></span>
<span id="cb119-2"><a href="#cb119-2" aria-hidden="true" tabindex="-1"></a>sample, target <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(test_loader))</span>
<span id="cb119-3"><a href="#cb119-3" aria-hidden="true" tabindex="-1"></a>sample <span class="op">=</span> sample.to(device)</span>
<span id="cb119-4"><a href="#cb119-4" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> model(sample)</span>
<span id="cb119-5"><a href="#cb119-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-6"><a href="#cb119-6" aria-hidden="true" tabindex="-1"></a>sample <span class="op">=</span> sample.cpu().numpy()</span>
<span id="cb119-7"><a href="#cb119-7" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> target.cpu().numpy()</span>
<span id="cb119-8"><a href="#cb119-8" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> preds.cpu().detach().numpy()</span>
<span id="cb119-9"><a href="#cb119-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-10"><a href="#cb119-10" aria-hidden="true" tabindex="-1"></a>ml_visual(sample, target, preds)</span></code></pre></div>
<div class="output display_data">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>duration_ms</th>
      <th>danceability</th>
      <th>energy</th>
      <th>key</th>
      <th>loudness</th>
      <th>mode</th>
      <th>speechiness</th>
      <th>acousticness</th>
      <th>instrumentalness</th>
      <th>liveness</th>
      <th>valence</th>
      <th>tempo</th>
      <th>time_signature</th>
      <th>track_genre_target_enc</th>
      <th>artists_target_enc</th>
      <th>explicit_enc</th>
      <th>popularity</th>
      <th>predicted_popularity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-0.182531</td>
      <td>-0.801713</td>
      <td>0.246650</td>
      <td>1.039759</td>
      <td>0.245466</td>
      <td>0.748811</td>
      <td>-0.335326</td>
      <td>0.780587</td>
      <td>-0.503755</td>
      <td>3.823774</td>
      <td>0.866666</td>
      <td>-1.262497</td>
      <td>0.225414</td>
      <td>0.983683</td>
      <td>0.613257</td>
      <td>-0.30251</td>
      <td>45.0</td>
      <td>35.856556</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1.153896</td>
      <td>0.494964</td>
      <td>0.238694</td>
      <td>-0.930096</td>
      <td>0.012982</td>
      <td>0.748811</td>
      <td>-0.469085</td>
      <td>0.651188</td>
      <td>-0.503750</td>
      <td>2.060848</td>
      <td>1.746144</td>
      <td>1.203250</td>
      <td>0.225414</td>
      <td>0.496016</td>
      <td>0.423640</td>
      <td>-0.30251</td>
      <td>37.0</td>
      <td>29.873962</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.489663</td>
      <td>0.039686</td>
      <td>1.332504</td>
      <td>-1.211504</td>
      <td>0.841664</td>
      <td>-1.335451</td>
      <td>0.918539</td>
      <td>-0.949616</td>
      <td>-0.431899</td>
      <td>0.313806</td>
      <td>-0.618418</td>
      <td>-0.272638</td>
      <td>0.225414</td>
      <td>-0.962407</td>
      <td>-0.453826</td>
      <td>-0.30251</td>
      <td>17.0</td>
      <td>26.164085</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.532040</td>
      <td>-1.643113</td>
      <td>-1.988699</td>
      <td>-0.367280</td>
      <td>-2.160372</td>
      <td>-1.335451</td>
      <td>-0.482557</td>
      <td>1.993330</td>
      <td>2.354289</td>
      <td>-0.580892</td>
      <td>-1.038870</td>
      <td>0.441346</td>
      <td>-2.062984</td>
      <td>-0.374213</td>
      <td>-0.559937</td>
      <td>-0.30251</td>
      <td>23.0</td>
      <td>35.964867</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.578262</td>
      <td>-0.940025</td>
      <td>1.113742</td>
      <td>1.039759</td>
      <td>1.089435</td>
      <td>0.748811</td>
      <td>0.254558</td>
      <td>-0.851651</td>
      <td>-0.503755</td>
      <td>-0.604716</td>
      <td>0.380638</td>
      <td>1.862487</td>
      <td>0.225414</td>
      <td>-0.761678</td>
      <td>-0.675422</td>
      <td>-0.30251</td>
      <td>25.0</td>
      <td>29.396473</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.753662</td>
      <td>1.100080</td>
      <td>0.708038</td>
      <td>1.039759</td>
      <td>0.687204</td>
      <td>0.748811</td>
      <td>1.457422</td>
      <td>-0.633778</td>
      <td>-0.503755</td>
      <td>-0.804302</td>
      <td>1.321834</td>
      <td>2.269206</td>
      <td>0.225414</td>
      <td>0.018907</td>
      <td>-0.145209</td>
      <td>3.30568</td>
      <td>31.0</td>
      <td>41.923275</td>
    </tr>
    <tr>
      <th>6</th>
      <td>-0.403861</td>
      <td>0.229865</td>
      <td>0.843273</td>
      <td>-0.085872</td>
      <td>0.723139</td>
      <td>-1.335451</td>
      <td>-0.426744</td>
      <td>-0.929501</td>
      <td>-0.503751</td>
      <td>0.149689</td>
      <td>-0.548985</td>
      <td>-0.005563</td>
      <td>0.225414</td>
      <td>0.986089</td>
      <td>1.345568</td>
      <td>-0.30251</td>
      <td>59.0</td>
      <td>25.103073</td>
    </tr>
    <tr>
      <th>7</th>
      <td>-0.175806</td>
      <td>-0.928499</td>
      <td>-0.922732</td>
      <td>0.476944</td>
      <td>0.217274</td>
      <td>0.748811</td>
      <td>-0.510463</td>
      <td>0.082432</td>
      <td>-0.503755</td>
      <td>-0.083250</td>
      <td>-0.934721</td>
      <td>-0.074064</td>
      <td>-2.062984</td>
      <td>0.443435</td>
      <td>1.020097</td>
      <td>-0.30251</td>
      <td>58.0</td>
      <td>23.098797</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-0.426109</td>
      <td>0.281732</td>
      <td>-0.473276</td>
      <td>0.195536</td>
      <td>0.378682</td>
      <td>0.748811</td>
      <td>0.254558</td>
      <td>1.244018</td>
      <td>-0.503755</td>
      <td>-0.692597</td>
      <td>0.993958</td>
      <td>0.360062</td>
      <td>0.225414</td>
      <td>-0.511088</td>
      <td>-0.223671</td>
      <td>-0.30251</td>
      <td>29.0</td>
      <td>20.275993</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.588058</td>
      <td>-1.406829</td>
      <td>1.300684</td>
      <td>-1.211504</td>
      <td>0.647299</td>
      <td>-1.335451</td>
      <td>0.027457</td>
      <td>-0.949750</td>
      <td>1.972353</td>
      <td>0.504392</td>
      <td>-1.692307</td>
      <td>0.271249</td>
      <td>0.225414</td>
      <td>-0.096352</td>
      <td>0.522406</td>
      <td>-0.30251</td>
      <td>23.0</td>
      <td>29.406485</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/2301598c218d6ed0c8e87a789fb4382f4d735ce9.png" /></p>
</div>
</div>
<div id="1850363e" class="cell markdown">
<p>You can tell that it's guessing around the mean 33 every time quite
consistently. Something to try next would be to train the model without
categorical variables: key, mode, time signature. However, considering
the knowledge that our features don't have a clear linear relationship
with the target, perhaps we can try K-Nearest Neighbors.</p>
</div>
<div id="19cf14ec" class="cell markdown">
<h3 id="svr-support-vector-regressor">SVR (Support Vector
Regressor)</h3>
</div>
<div id="bca44057" class="cell markdown">
<p>Credit:</p>
<p><a
href="https://medium.com/@niousha.rf/support-vector-regressor-theory-and-coding-exercise-in-python-ca6a7dfda927"
class="uri">https://medium.com/@niousha.rf/support-vector-regressor-theory-and-coding-exercise-in-python-ca6a7dfda927</a></p>
<p><a
href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html"
class="uri">https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html</a></p>
</div>
<div id="bc030118" class="cell markdown">
<p>Support Vector Regression is a type of Support Vector Machine used
for regression analysis. This model can help us see if a song feature
has a strong relationship with the target variable, popularity. In this
example, we will use instrumentalness as the X-value and popularity as
the Y-value, as instrumentalness is a continuous variable that has a
slightly higher correlation with popularity.</p>
<p>For now, we will split the dataset into testing and training sets,
and fit the data and model.</p>
<p>(Note: we are only testing the model on one x-variable because it
takes a while to fit the data).</p>
</div>
<div id="df171807" class="cell code">
<div class="sourceCode" id="cb120"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_iris</span>
<span id="cb120-3"><a href="#cb120-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb120-4"><a href="#cb120-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVR</span>
<span id="cb120-5"><a href="#cb120-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb120-6"><a href="#cb120-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-7"><a href="#cb120-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the X and Y data</span></span>
<span id="cb120-8"><a href="#cb120-8" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array(spotify_df[<span class="st">&#39;instrumentalness&#39;</span>]).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb120-9"><a href="#cb120-9" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> np.array(spotify_df[<span class="st">&#39;popularity&#39;</span>])</span>
<span id="cb120-10"><a href="#cb120-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-11"><a href="#cb120-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Split dataset into testing and training sets</span></span>
<span id="cb120-12"><a href="#cb120-12" aria-hidden="true" tabindex="-1"></a>X_train, X_test, Y_train, Y_test <span class="op">=</span> train_test_split(X, Y, test_size <span class="op">=</span> <span class="fl">0.2</span>, random_state <span class="op">=</span> <span class="dv">42</span>)</span>
<span id="cb120-13"><a href="#cb120-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-14"><a href="#cb120-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the data</span></span>
<span id="cb120-15"><a href="#cb120-15" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler().fit(X_train)</span>
<span id="cb120-16"><a href="#cb120-16" aria-hidden="true" tabindex="-1"></a>X_train_scaled <span class="op">=</span> scaler.transform(X_train)</span>
<span id="cb120-17"><a href="#cb120-17" aria-hidden="true" tabindex="-1"></a>X_test_scaled <span class="op">=</span> scaler.transform(X_test)</span>
<span id="cb120-18"><a href="#cb120-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-19"><a href="#cb120-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize and fit the model</span></span>
<span id="cb120-20"><a href="#cb120-20" aria-hidden="true" tabindex="-1"></a>svr_model <span class="op">=</span> SVR(kernel<span class="op">=</span><span class="st">&#39;linear&#39;</span>)</span>
<span id="cb120-21"><a href="#cb120-21" aria-hidden="true" tabindex="-1"></a>svr_model.fit(X_train_scaled, Y_train)</span>
<span id="cb120-22"><a href="#cb120-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-23"><a href="#cb120-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the test data</span></span>
<span id="cb120-24"><a href="#cb120-24" aria-hidden="true" tabindex="-1"></a>Y_pred <span class="op">=</span> svr_model.predict(X_test_scaled)</span></code></pre></div>
</div>
<div id="0b1dff40" class="cell markdown">
<p>Now let's graph and examine our model's performance.</p>
</div>
<div id="5a13cc8c" class="cell code">
<div class="sourceCode" id="cb121"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Model prediction for train dataset</span></span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a>Y_train_pred <span class="op">=</span> svr_model.predict(X_train_scaled)</span>
<span id="cb121-3"><a href="#cb121-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-4"><a href="#cb121-4" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_train, Y_train)</span>
<span id="cb121-5"><a href="#cb121-5" aria-hidden="true" tabindex="-1"></a>plt.plot(X_train, Y_train_pred, color <span class="op">=</span> <span class="st">&#39;orange&#39;</span>, label <span class="op">=</span> <span class="st">&#39;linear SVR&#39;</span>)</span>
<span id="cb121-6"><a href="#cb121-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Instrumentalness&#39;</span>)</span>
<span id="cb121-7"><a href="#cb121-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Popularity&#39;</span>)</span></code></pre></div>
<div class="output display_data">
<pre><code>Text(0, 0.5, &#39;Popularity&#39;)</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/b3875b3ad2c05a202b60ed5f8b0323a90319da81.png" /></p>
</div>
</div>
<div id="17756fed" class="cell markdown">
<p>Now we can evaluate our linear model's perfomance, and plot the
actual vs predicted target values.</p>
</div>
<div id="d7df7e81" class="cell code">
<div class="sourceCode" id="cb123"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> metrics</span>
<span id="cb123-2"><a href="#cb123-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb123-3"><a href="#cb123-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate results</span></span>
<span id="cb123-4"><a href="#cb123-4" aria-hidden="true" tabindex="-1"></a>r2_score <span class="op">=</span> <span class="bu">round</span>(metrics.r2_score(Y_test, Y_pred),<span class="dv">2</span>)</span>
<span id="cb123-5"><a href="#cb123-5" aria-hidden="true" tabindex="-1"></a>rmse <span class="op">=</span> <span class="bu">round</span>(np.sqrt(metrics.mean_squared_error(Y_test, Y_pred)),<span class="dv">2</span>)</span>
<span id="cb123-6"><a href="#cb123-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;r2: </span><span class="sc">{</span>r2_score<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb123-7"><a href="#cb123-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;rmse: </span><span class="sc">{</span>rmse<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb123-8"><a href="#cb123-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb123-9"><a href="#cb123-9" aria-hidden="true" tabindex="-1"></a>min_x <span class="op">=</span> <span class="bu">min</span>(<span class="bu">min</span>(Y_pred), <span class="bu">min</span>(Y_test))</span>
<span id="cb123-10"><a href="#cb123-10" aria-hidden="true" tabindex="-1"></a>max_x <span class="op">=</span> <span class="bu">max</span>(<span class="bu">max</span>(Y_pred), <span class="bu">max</span>(Y_test))</span>
<span id="cb123-11"><a href="#cb123-11" aria-hidden="true" tabindex="-1"></a>plt.scatter(Y_pred, Y_test)</span>
<span id="cb123-12"><a href="#cb123-12" aria-hidden="true" tabindex="-1"></a>plt.plot([min_x,max_x], [min_x,max_x], <span class="st">&#39;r--&#39;</span>, label <span class="op">=</span> <span class="st">&#39;1:1&#39;</span>)</span>
<span id="cb123-13"><a href="#cb123-13" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb123-14"><a href="#cb123-14" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Prediction&#39;</span>)</span>
<span id="cb123-15"><a href="#cb123-15" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Actual&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>r2: -0.0
rmse: 22.41
</code></pre>
</div>
<div class="output display_data">
<pre><code>Text(0, 0.5, &#39;Actual&#39;)</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/a6cadb7b77bc51de9e65c79c9171a4c0d233fd4a.png" /></p>
</div>
</div>
<div id="973ad4f4" class="cell markdown">
<p>Seems like the predictions of popularity scores based on
instrumentalness are consistently lower than the actual values.</p>
<p>R^2 of 0.0 tells us that approximately 0% of the variance in valence
can be explained by danceability.</p>
<p>Root mean squared error (RMSE) of 22.41 tells us the average
magnitude of the prediction errors between the actual and predict
valence scores.</p>
<p>So it looks like this model isn't the best when it comes to
predicting popularity based off instrumentalness. Let's look at another
model!</p>
</div>
<div id="466f1669" class="cell markdown">
<h3 id="linear-regression">Linear Regression</h3>
</div>
<div id="364c75ab" class="cell markdown">
<p>Credits:</p>
<p>HW 4</p>
<p><a
href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
class="uri">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html</a></p>
</div>
<div id="c3087638" class="cell markdown">
<p>Now we'll use a Linear Regression model to see the impact of
individual continuous variables on popularity. For now, we will use
instrumentalness, speechiness, loudness, and energy as X-values, and
popularity as our Y-values. The first three X-values had the highest
correlations with popularity, while the last one has one of the lowest
correlations. We will plot each of those variables below:</p>
</div>
<div id="a7943bce" class="cell code">
<div class="sourceCode" id="cb126"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb126-2"><a href="#cb126-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb126-3"><a href="#cb126-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb126-4"><a href="#cb126-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the data from the csv.</span></span>
<span id="cb126-5"><a href="#cb126-5" aria-hidden="true" tabindex="-1"></a>X_instrumentalness <span class="op">=</span> np.array(spotify_df[<span class="st">&#39;instrumentalness&#39;</span>]).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb126-6"><a href="#cb126-6" aria-hidden="true" tabindex="-1"></a>X_speechiness <span class="op">=</span> np.array(spotify_df[<span class="st">&#39;speechiness&#39;</span>]).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb126-7"><a href="#cb126-7" aria-hidden="true" tabindex="-1"></a>X_loudness <span class="op">=</span> np.array(spotify_df[<span class="st">&#39;loudness&#39;</span>]).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb126-8"><a href="#cb126-8" aria-hidden="true" tabindex="-1"></a>X_energy <span class="op">=</span> np.array(spotify_df[<span class="st">&#39;energy&#39;</span>]).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb126-9"><a href="#cb126-9" aria-hidden="true" tabindex="-1"></a>Y_popularity <span class="op">=</span> np.array(spotify_df[<span class="st">&#39;popularity&#39;</span>])</span>
<span id="cb126-10"><a href="#cb126-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb126-11"><a href="#cb126-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot each X-variable with popularity</span></span>
<span id="cb126-12"><a href="#cb126-12" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_instrumentalness , Y_popularity)</span>
<span id="cb126-13"><a href="#cb126-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Instrumentalness&#39;</span>)</span>
<span id="cb126-14"><a href="#cb126-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Popularity&#39;</span>)</span>
<span id="cb126-15"><a href="#cb126-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Popularity as a function of Instrumentalness&#39;</span>)</span>
<span id="cb126-16"><a href="#cb126-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb126-17"><a href="#cb126-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb126-18"><a href="#cb126-18" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_speechiness, Y_popularity)</span>
<span id="cb126-19"><a href="#cb126-19" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Speechiness&#39;</span>)</span>
<span id="cb126-20"><a href="#cb126-20" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Popularity&#39;</span>)</span>
<span id="cb126-21"><a href="#cb126-21" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Popularity as a function of Speechiness&#39;</span>)</span>
<span id="cb126-22"><a href="#cb126-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb126-23"><a href="#cb126-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb126-24"><a href="#cb126-24" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_loudness, Y_popularity)</span>
<span id="cb126-25"><a href="#cb126-25" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Loudness&#39;</span>)</span>
<span id="cb126-26"><a href="#cb126-26" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Popularity&#39;</span>)</span>
<span id="cb126-27"><a href="#cb126-27" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Popularity as a function of Loudness&#39;</span>)</span>
<span id="cb126-28"><a href="#cb126-28" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb126-29"><a href="#cb126-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb126-30"><a href="#cb126-30" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_energy, Y_popularity)</span>
<span id="cb126-31"><a href="#cb126-31" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Energy&#39;</span>)</span>
<span id="cb126-32"><a href="#cb126-32" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Popularity&#39;</span>)</span>
<span id="cb126-33"><a href="#cb126-33" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Popularity as a function of Energy&#39;</span>)</span>
<span id="cb126-34"><a href="#cb126-34" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/12950ec22c2f9bd8ab23b678d4c88414a966b072.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/1d0c36b0be50494ae252064a4963dc6e003e69c5.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/3a98c25bd6d7f66737a5fb12e56d9253f7a80cb8.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/bb310dac87e68c73027c705b1e7f11abd147d5a2.png" /></p>
</div>
</div>
<div id="b73309be" class="cell markdown">
<p>Wow, those are some crowded scatter plots! Anyways, we are now going
to divide the data into training and testing sets.</p>
</div>
<div id="86721acc" class="cell code">
<div class="sourceCode" id="cb127"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb127-2"><a href="#cb127-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-3"><a href="#cb127-3" aria-hidden="true" tabindex="-1"></a>random_state <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb127-4"><a href="#cb127-4" aria-hidden="true" tabindex="-1"></a>np.random.seed(random_state)</span>
<span id="cb127-5"><a href="#cb127-5" aria-hidden="true" tabindex="-1"></a>test_size <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb127-6"><a href="#cb127-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-7"><a href="#cb127-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> split_data(X, Y, test_size<span class="op">=</span>test_size, random_state<span class="op">=</span>random_state):</span>
<span id="cb127-8"><a href="#cb127-8" aria-hidden="true" tabindex="-1"></a>    X_train, X_test, Y_train, Y_test <span class="op">=</span> train_test_split(X, Y, test_size <span class="op">=</span> test_size, random_state <span class="op">=</span> random_state)</span>
<span id="cb127-9"><a href="#cb127-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-10"><a href="#cb127-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X_train, X_test, Y_train, Y_test</span>
<span id="cb127-11"><a href="#cb127-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-12"><a href="#cb127-12" aria-hidden="true" tabindex="-1"></a>X_train_instrumentalness, X_test_instrumentalness, Y_train_instrumentalness, Y_test_instrumentalness <span class="op">=</span> split_data(X_instrumentalness, Y_popularity)</span>
<span id="cb127-13"><a href="#cb127-13" aria-hidden="true" tabindex="-1"></a>X_train_speechiness, X_test_speechiness, Y_train_speechiness, Y_test_speechiness <span class="op">=</span> split_data(X_speechiness, Y_popularity)</span>
<span id="cb127-14"><a href="#cb127-14" aria-hidden="true" tabindex="-1"></a>X_train_loudness, X_test_loudness, Y_train_loudness, Y_test_loudness <span class="op">=</span> split_data(X_loudness, Y_popularity)</span>
<span id="cb127-15"><a href="#cb127-15" aria-hidden="true" tabindex="-1"></a>X_train_energy, X_test_energy, Y_train_energy, Y_test_energy <span class="op">=</span> split_data(X_energy, Y_popularity)</span></code></pre></div>
</div>
<div id="8df97261" class="cell markdown">
<p>Let's visualize out split dataset.</p>
</div>
<div id="483b6862" class="cell code">
<div class="sourceCode" id="cb128"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> draw_scatter(X_train, Y_train, X_test, Y_test, title, xlabel<span class="op">=</span><span class="st">&#39;Feature&#39;</span>, ylabel<span class="op">=</span><span class="st">&#39;Target&#39;</span>):</span>
<span id="cb128-2"><a href="#cb128-2" aria-hidden="true" tabindex="-1"></a>    plt.scatter(X_train, Y_train, color<span class="op">=</span><span class="st">&#39;blue&#39;</span>, label<span class="op">=</span><span class="st">&#39;Train&#39;</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb128-3"><a href="#cb128-3" aria-hidden="true" tabindex="-1"></a>    plt.scatter(X_test, Y_test, color<span class="op">=</span><span class="st">&#39;red&#39;</span>, label<span class="op">=</span><span class="st">&#39;Test&#39;</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb128-4"><a href="#cb128-4" aria-hidden="true" tabindex="-1"></a>    plt.title(title)</span>
<span id="cb128-5"><a href="#cb128-5" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(xlabel)</span>
<span id="cb128-6"><a href="#cb128-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> ylabel:</span>
<span id="cb128-7"><a href="#cb128-7" aria-hidden="true" tabindex="-1"></a>        plt.ylabel(ylabel)</span>
<span id="cb128-8"><a href="#cb128-8" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb128-9"><a href="#cb128-9" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb128-10"><a href="#cb128-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-11"><a href="#cb128-11" aria-hidden="true" tabindex="-1"></a>draw_scatter(X_train_instrumentalness, Y_train_instrumentalness, X_test_instrumentalness, Y_test_instrumentalness, <span class="st">&#39;Popularity as a function of Instrumentalness&#39;</span>)</span>
<span id="cb128-12"><a href="#cb128-12" aria-hidden="true" tabindex="-1"></a>draw_scatter(X_train_speechiness, Y_train_speechiness, X_test_speechiness, Y_test_speechiness, <span class="st">&#39;Popularity as a function of Speechiness&#39;</span>)</span>
<span id="cb128-13"><a href="#cb128-13" aria-hidden="true" tabindex="-1"></a>draw_scatter(X_train_loudness, Y_train_loudness, X_test_loudness, Y_test_loudness, <span class="st">&#39;Popularity as a function of Loudness&#39;</span>)</span>
<span id="cb128-14"><a href="#cb128-14" aria-hidden="true" tabindex="-1"></a>draw_scatter(X_train_energy, Y_train_energy, X_test_energy, Y_test_energy, <span class="st">&#39;Popularity as a function of energy&#39;</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/bb9cb2f8e06dbf4e6d63b9152cb355acb58235c9.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/54e59d8d1f78fc9a59947e9ea42e44ff1517fc20.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/89d769482110d7c0cbd63df8080bbbb103678e07.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/d8d76bb145df1862347ecefbf05ba170cea77034.png" /></p>
</div>
</div>
<div id="ddb3e8e5" class="cell markdown">
<p>Now we will fit a line for the given datasets.</p>
</div>
<div id="edc176ac" class="cell code">
<div class="sourceCode" id="cb129"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb129-2"><a href="#cb129-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-3"><a href="#cb129-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to fit the model</span></span>
<span id="cb129-4"><a href="#cb129-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fit_model(X_train, Y_train):</span>
<span id="cb129-5"><a href="#cb129-5" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> LinearRegression()</span>
<span id="cb129-6"><a href="#cb129-6" aria-hidden="true" tabindex="-1"></a>    model.fit(X_train, Y_train)</span>
<span id="cb129-7"><a href="#cb129-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb129-8"><a href="#cb129-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-9"><a href="#cb129-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to predict using the fitted model</span></span>
<span id="cb129-10"><a href="#cb129-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict_data(model, X_train, X_test):</span>
<span id="cb129-11"><a href="#cb129-11" aria-hidden="true" tabindex="-1"></a>    Y_train_pred <span class="op">=</span> model.predict(X_train)</span>
<span id="cb129-12"><a href="#cb129-12" aria-hidden="true" tabindex="-1"></a>    Y_test_pred <span class="op">=</span> model.predict(X_test)</span>
<span id="cb129-13"><a href="#cb129-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-14"><a href="#cb129-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Y_train_pred, Y_test_pred</span>
<span id="cb129-15"><a href="#cb129-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-16"><a href="#cb129-16" aria-hidden="true" tabindex="-1"></a>model_instrumentalness <span class="op">=</span> fit_model(X_train_instrumentalness, Y_train_instrumentalness)</span>
<span id="cb129-17"><a href="#cb129-17" aria-hidden="true" tabindex="-1"></a>Y_train_pred_instrumentalness, Y_test_pred_instrumentalness <span class="op">=</span> predict_data(</span>
<span id="cb129-18"><a href="#cb129-18" aria-hidden="true" tabindex="-1"></a>    model_instrumentalness, X_train_instrumentalness, X_test_instrumentalness)</span>
<span id="cb129-19"><a href="#cb129-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-20"><a href="#cb129-20" aria-hidden="true" tabindex="-1"></a>model_speechiness <span class="op">=</span> fit_model(X_train_speechiness, Y_train_speechiness)</span>
<span id="cb129-21"><a href="#cb129-21" aria-hidden="true" tabindex="-1"></a>Y_train_pred_speechiness, Y_test_pred_speechiness <span class="op">=</span> predict_data(</span>
<span id="cb129-22"><a href="#cb129-22" aria-hidden="true" tabindex="-1"></a>    model_speechiness, X_train_speechiness, X_test_speechiness)</span>
<span id="cb129-23"><a href="#cb129-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-24"><a href="#cb129-24" aria-hidden="true" tabindex="-1"></a>model_loudness <span class="op">=</span> fit_model(X_train_loudness, Y_train_loudness)</span>
<span id="cb129-25"><a href="#cb129-25" aria-hidden="true" tabindex="-1"></a>Y_train_pred_loudness, Y_test_pred_loudness <span class="op">=</span> predict_data(</span>
<span id="cb129-26"><a href="#cb129-26" aria-hidden="true" tabindex="-1"></a>    model_loudness, X_train_loudness, X_test_loudness)</span>
<span id="cb129-27"><a href="#cb129-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-28"><a href="#cb129-28" aria-hidden="true" tabindex="-1"></a>model_energy <span class="op">=</span> fit_model(X_train_energy, Y_train_energy)</span>
<span id="cb129-29"><a href="#cb129-29" aria-hidden="true" tabindex="-1"></a>Y_train_pred_energy, Y_test_pred_energy <span class="op">=</span> predict_data(</span>
<span id="cb129-30"><a href="#cb129-30" aria-hidden="true" tabindex="-1"></a>    model_energy, X_train_energy, X_test_energy)</span></code></pre></div>
</div>
<div id="2e756bfd" class="cell markdown">
<p>Now we plot the scatter plot with the regression line</p>
</div>
<div id="8b7b6dcb" class="cell code">
<div class="sourceCode" id="cb130"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> draw_scatter_with_regression(X_train, Y_train, X_test, Y_test, Y_train_pred, title, xlabel<span class="op">=</span><span class="st">&#39;Feature&#39;</span>, ylabel<span class="op">=</span><span class="st">&#39;Target&#39;</span>):</span>
<span id="cb130-2"><a href="#cb130-2" aria-hidden="true" tabindex="-1"></a>    plt.scatter(X_train, Y_train, color<span class="op">=</span><span class="st">&#39;blue&#39;</span>, label<span class="op">=</span><span class="st">&#39;Train&#39;</span>)</span>
<span id="cb130-3"><a href="#cb130-3" aria-hidden="true" tabindex="-1"></a>    plt.scatter(X_test, Y_test, color<span class="op">=</span><span class="st">&#39;orange&#39;</span>, label<span class="op">=</span><span class="st">&#39;Test&#39;</span>)</span>
<span id="cb130-4"><a href="#cb130-4" aria-hidden="true" tabindex="-1"></a>    plt.plot(X_train, Y_train_pred, color<span class="op">=</span><span class="st">&#39;green&#39;</span>, label<span class="op">=</span><span class="st">&#39;Regression Line&#39;</span>)</span>
<span id="cb130-5"><a href="#cb130-5" aria-hidden="true" tabindex="-1"></a>    plt.title(title)</span>
<span id="cb130-6"><a href="#cb130-6" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(xlabel)</span>
<span id="cb130-7"><a href="#cb130-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> ylabel:</span>
<span id="cb130-8"><a href="#cb130-8" aria-hidden="true" tabindex="-1"></a>        plt.ylabel(ylabel)</span>
<span id="cb130-9"><a href="#cb130-9" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb130-10"><a href="#cb130-10" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb130-11"><a href="#cb130-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-12"><a href="#cb130-12" aria-hidden="true" tabindex="-1"></a>draw_scatter_with_regression(X_train_instrumentalness, Y_train_instrumentalness,</span>
<span id="cb130-13"><a href="#cb130-13" aria-hidden="true" tabindex="-1"></a>                             X_test_instrumentalness, Y_test_instrumentalness,</span>
<span id="cb130-14"><a href="#cb130-14" aria-hidden="true" tabindex="-1"></a>                             Y_train_pred_instrumentalness,</span>
<span id="cb130-15"><a href="#cb130-15" aria-hidden="true" tabindex="-1"></a>                             <span class="st">&#39;Popularity as a function of Instrumentalness&#39;</span>)</span>
<span id="cb130-16"><a href="#cb130-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-17"><a href="#cb130-17" aria-hidden="true" tabindex="-1"></a>draw_scatter_with_regression(X_train_speechiness, Y_train_speechiness,</span>
<span id="cb130-18"><a href="#cb130-18" aria-hidden="true" tabindex="-1"></a>                             X_test_speechiness, Y_test_speechiness,</span>
<span id="cb130-19"><a href="#cb130-19" aria-hidden="true" tabindex="-1"></a>                             Y_train_pred_speechiness,</span>
<span id="cb130-20"><a href="#cb130-20" aria-hidden="true" tabindex="-1"></a>                             <span class="st">&#39;Popularity as a function of Speechiness&#39;</span>)</span>
<span id="cb130-21"><a href="#cb130-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-22"><a href="#cb130-22" aria-hidden="true" tabindex="-1"></a>draw_scatter_with_regression(X_train_loudness, Y_train_loudness,</span>
<span id="cb130-23"><a href="#cb130-23" aria-hidden="true" tabindex="-1"></a>                             X_test_loudness, Y_test_loudness,</span>
<span id="cb130-24"><a href="#cb130-24" aria-hidden="true" tabindex="-1"></a>                             Y_train_pred_loudness,</span>
<span id="cb130-25"><a href="#cb130-25" aria-hidden="true" tabindex="-1"></a>                             <span class="st">&#39;Popularity as a function of Loudness&#39;</span>)</span>
<span id="cb130-26"><a href="#cb130-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-27"><a href="#cb130-27" aria-hidden="true" tabindex="-1"></a>draw_scatter_with_regression(X_train_energy, Y_train_energy, X_test_energy,</span>
<span id="cb130-28"><a href="#cb130-28" aria-hidden="true" tabindex="-1"></a>                             Y_test_energy, Y_train_pred_energy,</span>
<span id="cb130-29"><a href="#cb130-29" aria-hidden="true" tabindex="-1"></a>                             <span class="st">&#39;Popularity as a function of Energy&#39;</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/9839b7061669d22cab9a17054af9e15092580adf.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/bc105bbb77db65cd0bf41de20f2f4a11f4108918.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/65c45c32c76b7e9811885ccc6deac47684e45c72.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/150cc012697d4bcc1fa0fd955c2ed14d5e7e8cd2.png" /></p>
</div>
</div>
<div id="63614245" class="cell markdown">
<p>Well, it doesn't look like the models performed well.</p>
<p>All of the MSE values for the models are high, indicating that our
models are making large errors when using their respective variables to
predict popularity.</p>
<p>Since the all the R^2 coefficients are close to 0, that means there
is no linear relationship between the observed and predicted values. So
instrumentalness, speechiness, loudness, and energy do not have a strong
relationship with popularity, though instrumentalness does have the
strongest relationship by far.</p>
<p>It seems that this model isn't the best one to use to predict
popularity. Maybe there is a better model?</p>
</div>
<div id="1edd21a7" class="cell markdown">
<h3 id="xgboost">XGBoost</h3>
</div>
<div id="a5a5d814" class="cell code" data-execution_count="5">
<div class="sourceCode" id="cb131"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">&quot;dataset.csv&quot;</span>)</span></code></pre></div>
</div>
<div id="35673990" class="cell code" data-execution_count="6">
<div class="sourceCode" id="cb132"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a>spotify_df <span class="op">=</span> df.drop(columns<span class="op">=</span><span class="st">&#39;Unnamed: 0&#39;</span>)</span></code></pre></div>
</div>
<div id="d4783838" class="cell code" data-execution_count="7">
<div class="sourceCode" id="cb133"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a>spotify_df <span class="op">=</span> spotify_df.dropna()</span>
<span id="cb133-2"><a href="#cb133-2" aria-hidden="true" tabindex="-1"></a>spotify_df <span class="op">=</span> spotify_df.drop_duplicates()</span></code></pre></div>
</div>
<div id="e202f17a" class="cell code" data-execution_count="8">
<div class="sourceCode" id="cb134"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a>freq_encoding <span class="op">=</span> spotify_df[<span class="st">&#39;track_genre&#39;</span>].value_counts()</span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a>spotify_df[<span class="st">&#39;track_genre_freq&#39;</span>] <span class="op">=</span> spotify_df[<span class="st">&#39;track_genre&#39;</span>].<span class="bu">map</span>(freq_encoding)</span></code></pre></div>
</div>
<div id="c9383d6f" class="cell code" data-execution_count="9">
<div class="sourceCode" id="cb135"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a>artist_encoding <span class="op">=</span> spotify_df[<span class="st">&#39;artists&#39;</span>].value_counts()</span>
<span id="cb135-2"><a href="#cb135-2" aria-hidden="true" tabindex="-1"></a>spotify_df[<span class="st">&#39;track_artist_freq&#39;</span>] <span class="op">=</span> spotify_df[<span class="st">&#39;artists&#39;</span>].<span class="bu">map</span>(artist_encoding)</span>
<span id="cb135-3"><a href="#cb135-3" aria-hidden="true" tabindex="-1"></a>spotify_df[<span class="st">&quot;explicitness_number&quot;</span>] <span class="op">=</span> spotify_df[<span class="st">&quot;explicit&quot;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x <span class="cf">else</span> <span class="dv">0</span>)</span>
<span id="cb135-4"><a href="#cb135-4" aria-hidden="true" tabindex="-1"></a>spotify_df.sample(<span class="dv">20</span>)</span>
<span id="cb135-5"><a href="#cb135-5" aria-hidden="true" tabindex="-1"></a>numerical_df <span class="op">=</span> spotify_df.drop(columns <span class="op">=</span> [<span class="st">&quot;track_id&quot;</span>, <span class="st">&quot;artists&quot;</span>, <span class="st">&quot;album_name&quot;</span>, <span class="st">&quot;track_name&quot;</span>, <span class="st">&quot;explicit&quot;</span>, <span class="st">&quot;track_genre&quot;</span>])</span>
<span id="cb135-6"><a href="#cb135-6" aria-hidden="true" tabindex="-1"></a>spotify_df[<span class="st">&quot;tryout&quot;</span>] <span class="op">=</span> np.log(spotify_df[<span class="st">&quot;instrumentalness&quot;</span>] <span class="op">+</span> <span class="dv">1</span>) <span class="op">+</span> np.log(spotify_df[<span class="st">&quot;loudness&quot;</span>] <span class="op">*</span> <span class="op">-</span> <span class="dv">1</span>) <span class="op">-</span> (spotify_df[<span class="st">&quot;track_genre_freq&quot;</span>])</span>
<span id="cb135-7"><a href="#cb135-7" aria-hidden="true" tabindex="-1"></a><span class="co">#spotify_df = spotify_df.drop(columns = [&quot;energy&quot;, &quot;acousticness&quot;])</span></span>
<span id="cb135-8"><a href="#cb135-8" aria-hidden="true" tabindex="-1"></a><span class="co">#spotify_df = spotify_df.drop(columns = [&quot;loudness&quot;])</span></span>
<span id="cb135-9"><a href="#cb135-9" aria-hidden="true" tabindex="-1"></a><span class="co">#spotify_df = spotify_df.drop(columns = [&quot;valence&quot;])</span></span>
<span id="cb135-10"><a href="#cb135-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Energy and acousticness and loudness are highly correlated with instrumentalness and instrumentalness is more correlated with popularity so its kept</span></span>
<span id="cb135-11"><a href="#cb135-11" aria-hidden="true" tabindex="-1"></a><span class="co">#Valence is highly correlated wtih danceabiliy and valence has no correlation with popularity so we get rid of it</span></span></code></pre></div>
<div class="output stream stderr">
<pre><code>c:\Users\mail2\anaconda3\envs\MindLabs\Lib\site-packages\pandas\core\arraylike.py:396: RuntimeWarning: invalid value encountered in log
  result = getattr(ufunc, method)(*inputs, **kwargs)
</code></pre>
</div>
</div>
<div id="ead7d4fc" class="cell code" data-execution_count="11">
<div class="sourceCode" id="cb137"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> numerical_df.drop(columns <span class="op">=</span> [<span class="st">&quot;popularity&quot;</span>])</span>
<span id="cb137-2"><a href="#cb137-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> numerical_df[<span class="st">&quot;popularity&quot;</span>]</span></code></pre></div>
</div>
<div id="44c3bc96" class="cell code" data-execution_count="17">
<div class="sourceCode" id="cb138"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb138-2"><a href="#cb138-2" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb138-3"><a href="#cb138-3" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb138-4"><a href="#cb138-4" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> scaler.fit_transform(X_test)</span></code></pre></div>
</div>
<div id="a37731c9" class="cell code" data-execution_count="18">
<div class="sourceCode" id="cb139"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a>X_train_tensor <span class="op">=</span> torch.tensor(X_train, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb139-2"><a href="#cb139-2" aria-hidden="true" tabindex="-1"></a>y_train_tensor <span class="op">=</span> torch.tensor(y_train.values, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb139-3"><a href="#cb139-3" aria-hidden="true" tabindex="-1"></a>X_test_tensor <span class="op">=</span> torch.tensor(X_test, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb139-4"><a href="#cb139-4" aria-hidden="true" tabindex="-1"></a>y_test_tensor <span class="op">=</span> torch.tensor(y_test.values, dtype<span class="op">=</span>torch.float32)</span></code></pre></div>
</div>
<div id="843a1994" class="cell code">
<div class="sourceCode" id="cb140"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Source: https://medium.com/@bharataameriya/using-xgboost-in-pytorch-for-enhanced-model-performance-d4c9f9e10225</span></span>
<span id="cb140-2"><a href="#cb140-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-3"><a href="#cb140-3" aria-hidden="true" tabindex="-1"></a>train_dmatrix <span class="op">=</span> xgb.DMatrix(X_train, label<span class="op">=</span>y_train)</span>
<span id="cb140-4"><a href="#cb140-4" aria-hidden="true" tabindex="-1"></a>test_dmatrix <span class="op">=</span> xgb.DMatrix(X_test, label<span class="op">=</span>y_test)</span>
<span id="cb140-5"><a href="#cb140-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-6"><a href="#cb140-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Define model parameters</span></span>
<span id="cb140-7"><a href="#cb140-7" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> {</span>
<span id="cb140-8"><a href="#cb140-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;objective&quot;</span>: <span class="st">&quot;reg:squarederror&quot;</span>,</span>
<span id="cb140-9"><a href="#cb140-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;eval_metric&quot;</span>: <span class="st">&quot;rmse&quot;</span>,</span>
<span id="cb140-10"><a href="#cb140-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;max_depth&quot;</span>: <span class="dv">23</span>,</span>
<span id="cb140-11"><a href="#cb140-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;eta&quot;</span>: <span class="fl">0.1</span></span>
<span id="cb140-12"><a href="#cb140-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb140-13"><a href="#cb140-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-14"><a href="#cb140-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Train XGBoost model</span></span>
<span id="cb140-15"><a href="#cb140-15" aria-hidden="true" tabindex="-1"></a>xgb_model <span class="op">=</span> xgb.train(params, train_dmatrix, num_boost_round<span class="op">=</span><span class="dv">100</span>)</span></code></pre></div>
</div>
<div id="e8908b3b" class="cell code">
<div class="sourceCode" id="cb141"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> xgb_model.predict(test_dmatrix)</span>
<span id="cb141-2"><a href="#cb141-2" aria-hidden="true" tabindex="-1"></a>preds_torch <span class="op">=</span> torch.tensor(preds, dtype<span class="op">=</span>torch.float32)</span></code></pre></div>
</div>
<div id="4c8c849c" class="cell code">
<div class="sourceCode" id="cb142"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a>rmse <span class="op">=</span> np.sqrt(mean_squared_error(y_test, preds))</span>
<span id="cb142-2"><a href="#cb142-2" aria-hidden="true" tabindex="-1"></a>r2 <span class="op">=</span> r2_score(y_test, preds)</span>
<span id="cb142-3"><a href="#cb142-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Root Mean Squared Error (RMSE): </span><span class="sc">{</span>rmse<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb142-4"><a href="#cb142-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;R² Score: </span><span class="sc">{</span>r2<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Root Mean Squared Error (RMSE): 18.9925
R² Score: 0.2809
</code></pre>
</div>
</div>
<div id="5a10d537" class="cell code">
<div class="sourceCode" id="cb144"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">4</span>))</span>
<span id="cb144-2"><a href="#cb144-2" aria-hidden="true" tabindex="-1"></a>plt.hist(residuals, bins<span class="op">=</span><span class="dv">30</span>, edgecolor<span class="op">=</span><span class="st">&#39;k&#39;</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb144-3"><a href="#cb144-3" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Prediction Errors Distribution&quot;</span>)</span>
<span id="cb144-4"><a href="#cb144-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Prediction Error&quot;</span>)</span>
<span id="cb144-5"><a href="#cb144-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;Frequency&quot;</span>)</span>
<span id="cb144-6"><a href="#cb144-6" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb144-7"><a href="#cb144-7" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb144-8"><a href="#cb144-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/d281d8a1d02bbe386da9dda263545dfbb774c822.png" /></p>
</div>
</div>
<div id="d861c5d6" class="cell code">
<div class="sourceCode" id="cb145"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb145-1"><a href="#cb145-1" aria-hidden="true" tabindex="-1"></a>xgb.plot_importance(xgb_model, importance_type<span class="op">=</span><span class="st">&#39;gain&#39;</span>, max_num_features<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb145-2"><a href="#cb145-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Top 10 Feature Importances&#39;</span>)</span>
<span id="cb145-3"><a href="#cb145-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_eede534cd4834ada93b64780dba4281d/913135cd5aaa910e7da2f535e2554d6b22b5eca3.png" /></p>
</div>
</div>
</body>
</html>
